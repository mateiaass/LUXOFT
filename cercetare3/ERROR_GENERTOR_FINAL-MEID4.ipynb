{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EpaF-9x5-t_"
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install rowordnet\n",
    "!pip install phunspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_12MmtN8_N4v"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import rowordnet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import phunspell\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "# 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\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v--JtrbxANfb"
   },
   "outputs": [],
   "source": [
    "wn = rowordnet.RoWordNet()\n",
    "pspell = phunspell.Phunspell('ro_RO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7KMgCyhE55L5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bc27be1d7145758506402022c07b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"mateiaassAI/MEID4\", streaming = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IEZBuJ6OXrgT"
   },
   "outputs": [],
   "source": [
    "dictio_words = {1: {0: 0.0, 1: 0.3, 2: 1.01},\n",
    "          3: {1: 0.0, 2: 0.3, 3: 1.01},\n",
    "          6: {2: 0.0, 3: 0.1, 4: 0.75, 5: 1.01},\n",
    "          9: {3: 0.0, 4: 0.2, 5: 0.5, 6: 0.7, 7: 1.01},\n",
    "          16: {3: 0.0, 4: 0.1, 5: 0.3, 6: 0.4, 7: 0.8, 8: 1.01},\n",
    "          20: {4: 0.0, 5: 0.1, 6: 0.3, 7: 0.5, 8: 0.8, 9: 1.01},\n",
    "          30: {5: 0.0, 6: 0.1, 7: 0.3, 8: 0.5, 9: 0.8, 10: 1.01},\n",
    "          100000000: None}\n",
    "\n",
    "def number_of_words_changed(sentence_length):\n",
    "  prob = random.randint(1, 100) / 100\n",
    "  keys = list(dictio_words.keys())\n",
    "  little_dict = {}\n",
    "  for i in range(len(dictio_words) - 1):\n",
    "      if sentence_length >= keys[i] and sentence_length < keys[i+1]:\n",
    "          little_dict = dictio_words[keys[i]]\n",
    "          values = list(little_dict.values())\n",
    "          for j in range(len(values) - 1):\n",
    "              if prob >= values[j] and prob < values[j+1]:\n",
    "                  return list(little_dict.keys())[list(little_dict.values()).index(values[j])]\n",
    "\n",
    "dictio_spell = {1: {0: 0.0, 1: 1.01},\n",
    "          3: {1: 0.0, 2: 1.01},\n",
    "          5: {1: 0.0, 2: 0.3, 3: 1.01},\n",
    "          10: {1: 0.0, 2: 0.4, 3: 0.7, 4: 1.01},\n",
    "          100000000: None}\n",
    "\n",
    "def number_of_misspellings(word_length):\n",
    "  prob = random.randint(1, 100) / 100\n",
    "\n",
    "  keys = list(dictio_spell.keys())\n",
    "  little_dict = {}\n",
    "  for i in range(len(dictio_spell) - 1):\n",
    "      if word_length >= keys[i] and word_length < keys[i+1]:\n",
    "          little_dict = dictio_spell[keys[i]]\n",
    "          values = list(little_dict.values())\n",
    "          for j in range(len(values) - 1):\n",
    "              if prob >= values[j] and prob < values[j+1]:\n",
    "                  return list(little_dict.keys())[list(little_dict.values()).index(values[j])]\n",
    "\n",
    "mispell_replacement_candidates = {\n",
    "    'a': ['ea', 'ă', 'â', 'au', 'q', 'w', 's', 'z'],\n",
    "    'ă': ['e', 'â', 'a', 'p', 'î', 'ț', 'ș'],\n",
    "    'â': ['î', 'ă', 'a', 'ț'],\n",
    "    'b': ['v', 'd', 'p', 'v', 'g', 'h', 'n'],\n",
    "    'c': ['k', 'g', 'x', 'd', 'f', 'v'],\n",
    "    'd': ['b', 'p', 'e', 'r', 's', 'f', 'x', 'c'],\n",
    "    'e': ['ie', 'i', 'ă', 'ea', 'esc', 'w', 's', 'd', 'r'],\n",
    "    'f': ['r', 'g', 'd', 'c', 'v'],\n",
    "    'g': ['c', 't', 'h', 'f', 'v', 'b'],\n",
    "    'h': ['y', 'g', 'j', 'b', 'n'],\n",
    "    'i': ['ii', 'iii', 'e', 'î', 'y', 'ie', 'l', 'u', 'o', 'j', 'k'],\n",
    "    'î': ['â', 'i', 'ă', 'ț'],\n",
    "    'j': ['ș', 'u', 'h', 'k', 'n', 'm'],\n",
    "    'k': ['c', 'i', 'j', 'l', 'm'],\n",
    "    'l': ['n', 'i', 'o', 'p', 'k'],\n",
    "    'm': ['n', 'j', 'k'],\n",
    "    'n': ['m', 'l', 'j', 'h', 'b'],\n",
    "    'o': ['u', 'or', 'i', 'k', 'l', 'p'],\n",
    "    'p': ['q', 'b', 'd', 'o', 'l'],\n",
    "    'q': ['c', 'p', 'w', 'a'],\n",
    "    'r': ['e', 'd', 't', 'f'],\n",
    "    's': ['ș', 'z', 'w', 'a', 'd', 's', 'z'],\n",
    "    'ș': ['j', 's', 'ă', 'ț', 'p', 'l'],\n",
    "    't': ['ț', 'r', 'f', 'g', 'y'],\n",
    "    'ț': ['t', 'ă', 'â', 'ș', 'î'],\n",
    "    'u': ['v', 'o', 'y', 'h', 'j', 'i'],\n",
    "    'v': ['w', 'u', 'b', 'vr', 'c', 'f', 'g'],\n",
    "    'w': ['v', 'q', 'e', 'a', 's'],\n",
    "    'x': ['cs', 'gz', 'cș', 's', 'd', 'z', 'c'],\n",
    "    'y': ['i', 't', 'u', 'g', 'h'],\n",
    "    'z': ['s', 'a', 'x'],\n",
    "}\n",
    "\n",
    "diacritice_to_normal = {\n",
    "    'ă': ['a', 'â', 'â', 'a'],\n",
    "    'â' : ['a', 'ă', 'î', 'a'],\n",
    "    'î' : ['i', 'i', 'i', 'i'],\n",
    "    'ț' : ['t', 't', 't', 't'],\n",
    "    'ș' : ['s', 's', 's', 's']\n",
    "}\n",
    "\n",
    "normal_to_diacritice = {\n",
    "    'a' : ['ă', 'â', 'a', 'a'],\n",
    "    'i' : ['î', 'î', 'i', 'i'],\n",
    "    't' : ['ț', 'ț', 't', 't'],\n",
    "    's' : ['ș', 'ș', 's', 's']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cTfV5ukCbpFx"
   },
   "outputs": [],
   "source": [
    "punctuation_dict = {\n",
    "    ' ': {' ': 0.00, ',': 0.95, '.': 0.975, '-----': 1.01},\n",
    "    ',': {' ': 0.00, ',': 0.41, '.': 0.95, '-----': 1.01},\n",
    "    ';': {' ': 0.00, ',': 0.85, ';': 0.90, '-----': 1.01},\n",
    "    ':': {' ': 0.00, ',': 0.90, ':': 0.92, '-----': 1.01},\n",
    "    '-': {' ': 0.00, '-': 0.95, '-----': 1.01},\n",
    "    '.': {' ': 0.00, ';': 0.20, '.': 0.23, '...': 0.97, '-----': 1.01},\n",
    "    '?': {' ': 0.00, '.': 0.80, '?': 0.84, '!': 0.96, '-----': 1.01},\n",
    "    '!': {' ': 0.00, '.': 0.80, '?': 0.90, '!': 0.97, '-----': 1.01},\n",
    "    '...': {' ': 0.00, '...': 0.80, '-----': 1.01}\n",
    "  }\n",
    "\n",
    "def punctuation_substitution(letter):\n",
    "  prob = random.randint(1, 100) / 100\n",
    "  keys = list(punctuation_dict.keys())\n",
    "  little_dict = punctuation_dict[letter]\n",
    "  values = list(little_dict.values())\n",
    "  for j in range(len(values) - 1):\n",
    "    if prob >= values[j] and prob < values[j+1]:\n",
    "      return list(little_dict.keys())[list(little_dict.values()).index(values[j])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nY0_ga4pbg9U"
   },
   "outputs": [],
   "source": [
    "def copy_word(sentence, word, isSpace = True):\n",
    "  if isSpace:\n",
    "    sentence = sentence + \" \" + word\n",
    "  else:\n",
    "    sentence = sentence + word\n",
    "  return sentence\n",
    "\n",
    "def concatenate(sentence, word1, word2, isSpace = True):\n",
    "  if isSpace:\n",
    "    sentence = sentence + \" \" + word1 + word2\n",
    "  else:\n",
    "    sentence = sentence + word1 + word2\n",
    "  return sentence\n",
    "\n",
    "def transpose(sentence, word1, word2, isSpace = True):\n",
    "  if isSpace:\n",
    "    sentence = sentence + \" \" + word2 + \" \" + word1\n",
    "  else:\n",
    "    sentence = sentence + word2 + \" \" + word1\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pboKH9FYyXSO"
   },
   "outputs": [],
   "source": [
    "def noisy_diacritice(letter):\n",
    "    if letter in diacritice_to_normal.keys():\n",
    "        r_nr = random.randint(0, 3)\n",
    "        # print(letter, diacritice_to_normal[letter][r_nr])\n",
    "        return diacritice_to_normal[letter][r_nr]\n",
    "    elif letter in normal_to_diacritice.keys():\n",
    "        r_nr = random.randint(0, 3)\n",
    "        return normal_to_diacritice[letter][r_nr]\n",
    "        # print(letter, normal_to_diacritice[letter][r_nr])\n",
    "    return letter\n",
    "\n",
    "def copy_letter(word, letter):\n",
    "    if letter is None:\n",
    "        letter = ''\n",
    "    return word + noisy_diacritice(letter)\n",
    "    \n",
    "def transpose_letters(word, letter1, letter2):\n",
    "    if letter2 is None:\n",
    "        letter2 = ''\n",
    "    return word + noisy_diacritice(letter2) + letter1\n",
    "\n",
    "def replace_letter(word, letter):\n",
    "    if letter is None:\n",
    "        letter = ''\n",
    "    return word + noisy_diacritice(letter)\n",
    "    \n",
    "def insert_letter(word, letter, new_letter):\n",
    "    if letter is None:\n",
    "        letter = ''\n",
    "    return word + noisy_diacritice(letter) + new_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "APZfrT8BvA2o"
   },
   "outputs": [],
   "source": [
    "alphabet = \"аăâbcdefghiîjklmnopqrsștțuvwxyz\"\n",
    "alphabet2 = \"аăâbcdefghiîjklmnopqrsștțuvwxyz----\"\n",
    "noisy_letter = \"-._&@(){}`\\';--,\\\":\"\n",
    "\n",
    "def misspell(word):\n",
    "  number_of_changed_letters = number_of_misspellings(len(word))\n",
    "  letters_to_be_changed = np.random.choice(np.arange(0, len(word)), size=number_of_changed_letters, replace=False).tolist()\n",
    "  wrong_word = \"\"\n",
    "  skip_flag = False\n",
    "  for i in range(len(word)):\n",
    "    if skip_flag == True:\n",
    "      skip_flag = False\n",
    "      continue\n",
    "    letter = word[i]\n",
    "\n",
    "    # Letter not to be changed\n",
    "    if i not in letters_to_be_changed:\n",
    "      wrong_word = copy_letter(wrong_word, letter)\n",
    "      continue\n",
    "\n",
    "    # Type of misspelling - Distribution of Probability\n",
    "    letter_error_action = random.randint(1, 100) / 100\n",
    "\n",
    "    # DELETION\n",
    "    if letter_error_action <= 0.25:\n",
    "      continue\n",
    "\n",
    "    # INSERTION\n",
    "    if letter_error_action > 0.25 and letter_error_action <= 0.45:\n",
    "      alphabet_letter = alphabet2[random.randint(0, len(alphabet2) - 1)]\n",
    "      wrong_word = insert_letter(wrong_word, letter, alphabet_letter)          \n",
    "      continue\n",
    "\n",
    "    if letter_error_action % 0.2 > 0.12:\n",
    "        wrong_word = copy_letter(wrong_word, noisy_letter[random.randint(0, len(noisy_letter) -1)])          \n",
    "\n",
    "    # TRANSPOSITION\n",
    "    if letter_error_action > 0.35 and letter_error_action <= 0.65 and i < len(word) - 1:\n",
    "      next_letter = word[i + 1]\n",
    "      wrong_word = transpose_letters(wrong_word, letter, next_letter)\n",
    "      skip_flag = True\n",
    "      continue\n",
    "\n",
    "    # REPLACEMENT\n",
    "    if letter_error_action > 0.60:\n",
    "      if letter.lower() not in alphabet:\n",
    "        alphabet_letter = letter\n",
    "      else:\n",
    "        # if letter_error_action <= 0.68 and i == 0:\n",
    "        #   alphabet_letter = letter.lower() if letter.islower() else letter.upper()\n",
    "\n",
    "        if letter_error_action <= 0.7 and i == len(word) - 1 and letter.lower() in ['a', 'i', 'l']:\n",
    "          continue\n",
    "\n",
    "        if letter_error_action > 0.90:\n",
    "          alphabet_letter = alphabet[random.randint(0, len(alphabet) - 1)]\n",
    "        else:\n",
    "            try:\n",
    "                alphabet_letter = random.choice(mispell_replacement_candidates[letter.lower()])\n",
    "            except KeyError:\n",
    "                alphabet_letter = letter\n",
    "\n",
    "      wrong_word = replace_letter(wrong_word, alphabet_letter)\n",
    "      continue\n",
    "\n",
    "    # DEFAULT\n",
    "    wrong_word = copy_letter(wrong_word, letter)\n",
    "\n",
    "  return wrong_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PcO7ZeN3xlWW"
   },
   "outputs": [],
   "source": [
    "def morphologic_dex(word):\n",
    "  if len(word) <= 3:\n",
    "    return word\n",
    "\n",
    "  url = f'https://dexonline.ro/definitie/{word}/paradigma'\n",
    "  response = requests.get(url)\n",
    "  try :\n",
    "      if response.status_code == 200:\n",
    "        action = random.randint(1, 100) / 100\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        if action < 0.7:\n",
    "            para_lexemes = soup.find_all('div', class_='paraLexeme')\n",
    "        \n",
    "            for para_lexeme in para_lexemes:\n",
    "              lexeme_name = para_lexeme.find('span', class_='lexemeName').text\n",
    "              if lexeme_name == word:\n",
    "                table = para_lexeme.find('table', class_='lexeme')\n",
    "        \n",
    "                if table:\n",
    "                  unique_cells = set()\n",
    "                  form_cells = table.find_all('td', class_='form')\n",
    "        \n",
    "                  for cell in form_cells:\n",
    "                    if not cell.find(class_='elisionHidden') and not cell.find(class_='notRecommendedHidden'):\n",
    "                      text = cell.get_text(strip=True)\n",
    "                      if '—' not in text:\n",
    "                        text = text.replace(')', ' ').replace('(', '')\n",
    "                        unique_cells.add(text)\n",
    "        \n",
    "                  if unique_cells:\n",
    "                    random_word = random.choice(list(unique_cells))\n",
    "                    return random_word\n",
    "                    # return unique_cells\n",
    "        else:\n",
    "            spans_synonyms = soup.find_all('span', class_='badge-relation badge-relation-1')\n",
    "            unique_cells = set()\n",
    "    \n",
    "            for spans in spans_synonyms:\n",
    "                text = spans.text.replace('\\'', ' ').replace(' ', '')\n",
    "                unique_cells.add(text)\n",
    "    \n",
    "            if unique_cells:\n",
    "                return random.choice(list(unique_cells))\n",
    "            # return unique_cells\n",
    "      return word\n",
    "  except Exception as e:\n",
    "      return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c9GUbngn7ttP"
   },
   "outputs": [],
   "source": [
    "lista_conjunctii = ['și', 'dar', 'iar', 'că', 'să', 'ci', 'fie', 'sau', 'ori', 'ci și', 'ca să', 'încât să', 'nici', 'însă', 'ba', 'deci', 'așadar', 'totuși', 'însăși', 'chiar', 'tot', 'încă', 'atât', 'pe când', 'în timp ce',\n",
    "                    'cu toate că', 'întrucât', 'precum', 'totodată', 'care', 'pe care']\n",
    "\n",
    "lista_prepozitii = ['la', 'în', 'către', 'contrar', 'fără', 'după', 'cu', 'lângă', 'asupra', 'de', 'de la', 'despre', 'dimprejurul', 'din', 'dinaintea', 'înspre', 'între', 'înăuntrul', 'împotriva', 'împrejurul', 'înaintea',\n",
    "                    'înapoia', 'întru', 'dedesubtul', 'datorită', 'printre', 'prin', 'primprejur', 'peste', 'pentru', 'pe', 'până', 'via', 'spre', 'sub', 'din cauza', 'din pricina', 'în vederea', 'cu excepția', 'cu tot cu', 'a']\n",
    "\n",
    "lista_articole_posesive = ['a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor']\n",
    "lista_articole_demonstrative = ['cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor', 'cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor', 'cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor', 'cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor']\n",
    "lista_articole_nehotarate = ['un', 'o', 'niste', 'unor', 'unui', 'unei', 'un', 'o', 'niste', 'unor', 'unui', 'unei', 'un', 'o', 'niste', 'unor', 'unui', 'unei','un', 'o', 'niste', 'unor', 'unui', 'unei']\n",
    "\n",
    "def substitute(word_metadata):\n",
    "  action = random.randint(1, 100) / 100\n",
    "\n",
    "  if len(word_metadata.text) > 8 and action > 0.6:\n",
    "    action = 0.5\n",
    "\n",
    "  # RoWORDNET\n",
    "  if action <= 0.2:\n",
    "    word = word_metadata.lemma_.lower()\n",
    "    syn_list = []\n",
    "    synset_ids = wn.synsets(literal=word)\n",
    "    for s in synset_ids:\n",
    "      if word in wn.synset(s).literals:\n",
    "        for literal in wn.synset(s).literals:\n",
    "          if literal != word and literal not in syn_list:\n",
    "            syn_list.append(literal)\n",
    "    if len(syn_list) > 0:\n",
    "      return random.choice(syn_list)\n",
    "    else:\n",
    "      return word_metadata.text\n",
    "\n",
    "  # DEXONLINE\n",
    "  elif action > 0.2 and action <= 0.7:\n",
    "\n",
    "    if word_metadata.pos_ == 'CCONJ' and action <= 0.3:\n",
    "      return random.choice(lista_conjunctii)\n",
    "\n",
    "    if word_metadata.pos_ == 'ADP' and action <= 0.3:\n",
    "      return random.choice(lista_prepozitii)\n",
    "\n",
    "    if word_metadata.pos_ == 'DET' and word_metadata.text in lista_articole_posesive and action <= 0.3:\n",
    "      return random.choice(lista_articole_posesive)\n",
    "    if word_metadata.pos_ == 'DET' and word_metadata.text in lista_articole_demonstrative and action <= 0.3:\n",
    "      return random.choice(lista_articole_demonstrative)\n",
    "\n",
    "    if word_metadata.pos_ == 'DET' and word_metadata.text in lista_articole_nehotarate and action <= 0.3:\n",
    "      return random.choice(lista_articole_nehotarate)\n",
    "    return morphologic_dex(word_metadata.lemma_)\n",
    "\n",
    "  # SPELLCHECKER\n",
    "  elif action > 0.7:\n",
    "    sugestions = list(pspell.suggest(word_metadata.text))\n",
    "    if len(sugestions) == 0:\n",
    "      return morphologic_dex(word_metadata.lemma_)\n",
    "    return random.choice(sugestions)\n",
    "\n",
    "  return word_metadata.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4YRo4YmSGLOy"
   },
   "outputs": [],
   "source": [
    "def save_data(data, counter):\n",
    "  output_file = f'MEID5/{counter}.jsonl'\n",
    "  with open(output_file, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    for example_parsed in data:\n",
    "      json.dump(example_parsed, json_file, ensure_ascii=False)#, indent=4)\n",
    "      json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wrong': 'HOTĂRÂREA Nr. 8 din 18 ianuarie 2011', 'right': 'DECIZIE nr. 8 din 18 ianuarie 2011'}\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset[\"train\"])\n",
    "for example in iterator:\n",
    "    print(example)\n",
    "    break\n",
    "# dataset[\"train\"][0][\"wrong\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pqr52hP3TGBU",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "200100 2024-09-23 13:43:03.948624\n",
      "200200 2024-09-23 13:43:55.354864\n",
      "200300 2024-09-23 13:44:43.506453\n",
      "200400 2024-09-23 13:45:22.106168\n",
      "200500 2024-09-23 13:46:15.743884\n",
      "200600 2024-09-23 13:46:55.685694\n",
      "200700 2024-09-23 13:47:51.722473\n",
      "200800 2024-09-23 13:48:38.346885\n",
      "200900 2024-09-23 13:49:29.268820\n",
      "201000 2024-09-23 13:50:11.525249\n",
      "201100 2024-09-23 13:50:49.884936\n",
      "201200 2024-09-23 13:51:47.587687\n",
      "201300 2024-09-23 13:52:32.059734\n",
      "201400 2024-09-23 13:53:04.461320\n",
      "201500 2024-09-23 13:53:39.702948\n",
      "201600 2024-09-23 13:54:32.989100\n",
      "201700 2024-09-23 13:55:23.513088\n",
      "201800 2024-09-23 13:56:08.596414\n",
      "201900 2024-09-23 13:56:51.032613\n",
      "202000 2024-09-23 13:57:41.529878\n",
      "202100 2024-09-23 13:58:20.112716\n",
      "202200 2024-09-23 13:59:08.220453\n",
      "202300 2024-09-23 14:00:08.609343\n",
      "202400 2024-09-23 14:01:08.011610\n",
      "202500 2024-09-23 14:01:54.003674\n",
      "202600 2024-09-23 14:02:40.077893\n",
      "202700 2024-09-23 14:03:36.638023\n",
      "202800 2024-09-23 14:04:20.081899\n",
      "202900 2024-09-23 14:05:00.638304\n",
      "203000 2024-09-23 14:05:51.730285\n",
      "203100 2024-09-23 14:06:38.597588\n",
      "203200 2024-09-23 14:07:25.742116\n",
      "203300 2024-09-23 14:08:17.750815\n",
      "203400 2024-09-23 14:09:19.545072\n",
      "203500 2024-09-23 14:10:04.291459\n",
      "203600 2024-09-23 14:10:51.079370\n",
      "203700 2024-09-23 14:11:34.481441\n",
      "203800 2024-09-23 14:12:08.935403\n",
      "203900 2024-09-23 14:13:08.330422\n",
      "204000 2024-09-23 14:13:56.545343\n",
      "204100 2024-09-23 14:14:48.295833\n",
      "204200 2024-09-23 14:15:45.787385\n",
      "204300 2024-09-23 14:16:36.066301\n",
      "204400 2024-09-23 14:17:25.717042\n",
      "204500 2024-09-23 14:18:17.450641\n",
      "204600 2024-09-23 14:18:56.207976\n",
      "204700 2024-09-23 14:19:54.382726\n",
      "204800 2024-09-23 14:20:58.370080\n",
      "204900 2024-09-23 14:21:40.837507\n",
      "205000 2024-09-23 14:22:37.872480\n",
      "205100 2024-09-23 14:23:20.846437\n",
      "205200 2024-09-23 14:23:52.841434\n",
      "205300 2024-09-23 14:24:40.397642\n",
      "205400 2024-09-23 14:25:29.457503\n",
      "205500 2024-09-23 14:26:10.695331\n",
      "205600 2024-09-23 14:26:56.904578\n",
      "205700 2024-09-23 14:27:35.043357\n",
      "205800 2024-09-23 14:28:17.702632\n",
      "205900 2024-09-23 14:28:55.424074\n",
      "206000 2024-09-23 14:29:35.522940\n",
      "206100 2024-09-23 14:30:13.309653\n",
      "206200 2024-09-23 14:30:55.722407\n",
      "206300 2024-09-23 14:31:56.423912\n",
      "206400 2024-09-23 14:32:48.939965\n",
      "206500 2024-09-23 14:33:43.399229\n",
      "206600 2024-09-23 14:34:39.789204\n",
      "206700 2024-09-23 14:35:29.473310\n",
      "206800 2024-09-23 14:36:07.169300\n",
      "206900 2024-09-23 14:36:51.931809\n",
      "207000 2024-09-23 14:37:45.431881\n",
      "207100 2024-09-23 14:38:46.073595\n",
      "207200 2024-09-23 14:39:43.359373\n",
      "207300 2024-09-23 14:40:44.019706\n",
      "207400 2024-09-23 14:41:30.839335\n",
      "207500 2024-09-23 14:42:14.490122\n",
      "207600 2024-09-23 14:42:48.422598\n",
      "207700 2024-09-23 14:43:33.245256\n",
      "207800 2024-09-23 14:43:58.300780\n",
      "207900 2024-09-23 14:44:13.239007\n",
      "208000 2024-09-23 14:44:31.206252\n",
      "208100 2024-09-23 14:45:00.968177\n",
      "208200 2024-09-23 14:45:58.075020\n",
      "208300 2024-09-23 14:46:52.061228\n",
      "208400 2024-09-23 14:47:51.696993\n",
      "208500 2024-09-23 14:48:40.842426\n",
      "208600 2024-09-23 14:49:27.681476\n",
      "208700 2024-09-23 14:50:14.616991\n",
      "208800 2024-09-23 14:50:58.668799\n",
      "208900 2024-09-23 14:51:41.849423\n",
      "209000 2024-09-23 14:52:27.879359\n",
      "209100 2024-09-23 14:53:15.585682\n",
      "209200 2024-09-23 14:54:07.377481\n",
      "209300 2024-09-23 14:54:51.847896\n",
      "209400 2024-09-23 14:55:35.621715\n",
      "209500 2024-09-23 14:56:10.050048\n",
      "209600 2024-09-23 14:57:02.442228\n",
      "209700 2024-09-23 14:58:04.020057\n",
      "209800 2024-09-23 14:58:51.210549\n",
      "209900 2024-09-23 14:59:47.462206\n",
      "210000 2024-09-23 15:00:42.128043\n",
      "210000 2024-09-23 15:00:42.439207 9\n",
      "210100 2024-09-23 15:01:20.881805\n",
      "210200 2024-09-23 15:01:38.711213\n",
      "210300 2024-09-23 15:02:25.623765\n",
      "210400 2024-09-23 15:03:09.350039\n",
      "210500 2024-09-23 15:03:46.976053\n",
      "210600 2024-09-23 15:04:09.496148\n",
      "210700 2024-09-23 15:04:55.438403\n",
      "210800 2024-09-23 15:05:47.524370\n",
      "210900 2024-09-23 15:06:30.001629\n",
      "211000 2024-09-23 15:07:16.582498\n",
      "211100 2024-09-23 15:07:59.966937\n",
      "211200 2024-09-23 15:08:30.840266\n",
      "211300 2024-09-23 15:09:18.602004\n",
      "211400 2024-09-23 15:10:01.012473\n",
      "211500 2024-09-23 15:10:47.120440\n",
      "211600 2024-09-23 15:11:31.459343\n",
      "211700 2024-09-23 15:12:34.046600\n",
      "211800 2024-09-23 15:13:20.197227\n",
      "211900 2024-09-23 15:14:05.788688\n",
      "212000 2024-09-23 15:14:51.841203\n",
      "212100 2024-09-23 15:15:44.989145\n",
      "212200 2024-09-23 15:16:36.255609\n",
      "212300 2024-09-23 15:17:28.679917\n",
      "212400 2024-09-23 15:18:18.948198\n",
      "212500 2024-09-23 15:19:10.843948\n",
      "212600 2024-09-23 15:20:07.000788\n",
      "212700 2024-09-23 15:20:54.913533\n",
      "212800 2024-09-23 15:21:24.511681\n",
      "212900 2024-09-23 15:21:45.734950\n",
      "213000 2024-09-23 15:22:40.980197\n",
      "213100 2024-09-23 15:23:19.107287\n",
      "213200 2024-09-23 15:23:53.099892\n",
      "213300 2024-09-23 15:24:25.690024\n",
      "213400 2024-09-23 15:24:59.817014\n",
      "213500 2024-09-23 15:25:45.540283\n",
      "213600 2024-09-23 15:26:35.144095\n",
      "213700 2024-09-23 15:27:20.123533\n",
      "213800 2024-09-23 15:28:23.259765\n",
      "213900 2024-09-23 15:29:08.117188\n",
      "214000 2024-09-23 15:29:29.095953\n",
      "214100 2024-09-23 15:30:21.617091\n",
      "214200 2024-09-23 15:31:16.842130\n",
      "214300 2024-09-23 15:31:58.655410\n",
      "214400 2024-09-23 15:32:47.750838\n",
      "214500 2024-09-23 15:33:32.800859\n",
      "214600 2024-09-23 15:34:14.673219\n",
      "214700 2024-09-23 15:35:11.990842\n",
      "214800 2024-09-23 15:35:58.577828\n",
      "214900 2024-09-23 15:36:35.071756\n",
      "215000 2024-09-23 15:37:23.078458\n",
      "215100 2024-09-23 15:38:19.388826\n",
      "215200 2024-09-23 15:38:48.145798\n",
      "215300 2024-09-23 15:39:07.116522\n",
      "215400 2024-09-23 15:39:29.086012\n",
      "215500 2024-09-23 15:39:53.165575\n",
      "215600 2024-09-23 15:40:17.399042\n",
      "215700 2024-09-23 15:40:43.650207\n",
      "215800 2024-09-23 15:41:05.437251\n",
      "215900 2024-09-23 15:41:24.154241\n",
      "216000 2024-09-23 15:41:54.559444\n",
      "216100 2024-09-23 15:42:26.246818\n",
      "216200 2024-09-23 15:42:45.657314\n",
      "216300 2024-09-23 15:43:08.374541\n",
      "216400 2024-09-23 15:43:33.751995\n",
      "216500 2024-09-23 15:43:51.157341\n",
      "216600 2024-09-23 15:44:12.204655\n",
      "216700 2024-09-23 15:44:34.514866\n",
      "216800 2024-09-23 15:45:07.437392\n",
      "216900 2024-09-23 15:45:53.115606\n",
      "217000 2024-09-23 15:46:29.078055\n",
      "217100 2024-09-23 15:47:20.838780\n",
      "217200 2024-09-23 15:48:08.177352\n",
      "217300 2024-09-23 15:48:47.937952\n",
      "217400 2024-09-23 15:49:31.828491\n",
      "217500 2024-09-23 15:50:18.453982\n",
      "217600 2024-09-23 15:51:31.474250\n",
      "217700 2024-09-23 15:52:18.645981\n",
      "217800 2024-09-23 15:53:02.898027\n",
      "217900 2024-09-23 15:53:45.191043\n",
      "218000 2024-09-23 15:54:26.675913\n",
      "218100 2024-09-23 15:55:17.455678\n",
      "218200 2024-09-23 15:56:12.964465\n",
      "218300 2024-09-23 15:56:53.986116\n",
      "218400 2024-09-23 15:57:43.218095\n",
      "218500 2024-09-23 15:58:33.384032\n",
      "218600 2024-09-23 15:59:26.628778\n",
      "218700 2024-09-23 16:00:16.621329\n",
      "218800 2024-09-23 16:00:59.931700\n",
      "218900 2024-09-23 16:01:42.751807\n",
      "219000 2024-09-23 16:02:27.824489\n",
      "219100 2024-09-23 16:03:24.974491\n",
      "219200 2024-09-23 16:04:08.060195\n",
      "219300 2024-09-23 16:05:03.667653\n",
      "219400 2024-09-23 16:05:51.326980\n",
      "219500 2024-09-23 16:06:26.748342\n",
      "219600 2024-09-23 16:07:32.154988\n",
      "219700 2024-09-23 16:08:28.242640\n",
      "219800 2024-09-23 16:09:30.000890\n",
      "219900 2024-09-23 16:10:24.708710\n",
      "220000 2024-09-23 16:11:18.254648\n",
      "220000 2024-09-23 16:11:18.726718 10\n",
      "220100 2024-09-23 16:12:12.957880\n",
      "220200 2024-09-23 16:13:14.788018\n",
      "220300 2024-09-23 16:14:08.482627\n",
      "220400 2024-09-23 16:14:43.047863\n",
      "220500 2024-09-23 16:15:23.794117\n",
      "220600 2024-09-23 16:16:01.793067\n",
      "220700 2024-09-23 16:16:45.449199\n",
      "220800 2024-09-23 16:17:29.015970\n",
      "220900 2024-09-23 16:17:54.941560\n",
      "221000 2024-09-23 16:18:35.336401\n",
      "221100 2024-09-23 16:19:21.782698\n",
      "221200 2024-09-23 16:20:14.345241\n",
      "221300 2024-09-23 16:21:07.094307\n",
      "221400 2024-09-23 16:22:01.066056\n",
      "221500 2024-09-23 16:22:45.878100\n",
      "221600 2024-09-23 16:23:39.115941\n",
      "221700 2024-09-23 16:24:29.928374\n",
      "221800 2024-09-23 16:25:28.289203\n",
      "221900 2024-09-23 16:26:20.532343\n",
      "222000 2024-09-23 16:27:07.756384\n",
      "222100 2024-09-23 16:28:09.844066\n",
      "222200 2024-09-23 16:28:52.055123\n",
      "222300 2024-09-23 16:29:43.172853\n",
      "222400 2024-09-23 16:30:34.818174\n",
      "222500 2024-09-23 16:31:21.570231\n",
      "222600 2024-09-23 16:32:11.850350\n",
      "222700 2024-09-23 16:32:50.238840\n",
      "222800 2024-09-23 16:33:42.928653\n",
      "222900 2024-09-23 16:34:35.477082\n",
      "223000 2024-09-23 16:35:18.485281\n",
      "223100 2024-09-23 16:36:02.597073\n",
      "223200 2024-09-23 16:36:44.444601\n",
      "223300 2024-09-23 16:37:35.089319\n",
      "223400 2024-09-23 16:38:16.103126\n",
      "223500 2024-09-23 16:39:03.365161\n",
      "223600 2024-09-23 16:39:36.136265\n",
      "223700 2024-09-23 16:40:16.817132\n",
      "223800 2024-09-23 16:40:36.575692\n",
      "223900 2024-09-23 16:41:10.440267\n",
      "224000 2024-09-23 16:41:31.958698\n",
      "224100 2024-09-23 16:41:48.263267\n",
      "224200 2024-09-23 16:42:11.129385\n",
      "224300 2024-09-23 16:42:54.814776\n",
      "224400 2024-09-23 16:43:40.854603\n",
      "224500 2024-09-23 16:44:28.430842\n",
      "224600 2024-09-23 16:44:56.384485\n",
      "224700 2024-09-23 16:45:43.709946\n",
      "224800 2024-09-23 16:46:33.336797\n",
      "224900 2024-09-23 16:47:26.093430\n",
      "225000 2024-09-23 16:48:16.036536\n",
      "225100 2024-09-23 16:49:13.640166\n",
      "225200 2024-09-23 16:49:36.895996\n",
      "225300 2024-09-23 16:50:12.534373\n",
      "225400 2024-09-23 16:51:17.747722\n",
      "225500 2024-09-23 16:52:11.365302\n",
      "225600 2024-09-23 16:53:14.161354\n",
      "225700 2024-09-23 16:54:07.631853\n",
      "225800 2024-09-23 16:54:53.265766\n",
      "225900 2024-09-23 16:55:30.245840\n",
      "226000 2024-09-23 16:56:21.436123\n",
      "226100 2024-09-23 16:57:12.448051\n",
      "226200 2024-09-23 16:57:49.652236\n",
      "226300 2024-09-23 16:58:35.824239\n",
      "226400 2024-09-23 16:59:08.875211\n",
      "226500 2024-09-23 16:59:52.885437\n",
      "226600 2024-09-23 17:00:29.423227\n",
      "226700 2024-09-23 17:01:10.167131\n",
      "226800 2024-09-23 17:01:48.729586\n",
      "226900 2024-09-23 17:02:22.677253\n",
      "227000 2024-09-23 17:02:59.918379\n",
      "227100 2024-09-23 17:03:45.277540\n",
      "227200 2024-09-23 17:04:20.646550\n",
      "227300 2024-09-23 17:05:00.631317\n",
      "227400 2024-09-23 17:05:45.732751\n",
      "227500 2024-09-23 17:06:33.824055\n",
      "227600 2024-09-23 17:07:20.547353\n",
      "227700 2024-09-23 17:08:06.215303\n",
      "227800 2024-09-23 17:08:58.468105\n",
      "227900 2024-09-23 17:09:49.405617\n",
      "228000 2024-09-23 17:10:28.681008\n",
      "228100 2024-09-23 17:11:18.864681\n",
      "228200 2024-09-23 17:12:04.031206\n",
      "228300 2024-09-23 17:13:07.256589\n",
      "228400 2024-09-23 17:14:04.431434\n",
      "228500 2024-09-23 17:14:44.314344\n",
      "228600 2024-09-23 17:15:34.830549\n",
      "228700 2024-09-23 17:16:32.907499\n",
      "228800 2024-09-23 17:17:39.027000\n",
      "228900 2024-09-23 17:18:41.437272\n",
      "229000 2024-09-23 17:19:01.931376\n",
      "229100 2024-09-23 17:19:13.196071\n",
      "229200 2024-09-23 17:19:58.993799\n",
      "229300 2024-09-23 17:21:06.732934\n",
      "229400 2024-09-23 17:21:54.894391\n",
      "229500 2024-09-23 17:22:55.951302\n",
      "229600 2024-09-23 17:23:45.940427\n",
      "229700 2024-09-23 17:24:46.802633\n",
      "229800 2024-09-23 17:25:40.037752\n",
      "229900 2024-09-23 17:26:43.713721\n",
      "230000 2024-09-23 17:27:39.526328\n",
      "230000 2024-09-23 17:27:39.625759 11\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "iterator = iter(dataset[\"train\"])\n",
    "count = 0\n",
    "data = []\n",
    "nlp_cuv = spacy.load(\"ro_core_news_sm\")\n",
    "\n",
    "punctuation_list = [' ', ',', ';', ':', '-', '.', '?', '!', '...']\n",
    "\n",
    "contor_file = 8\n",
    "breakline = 10000\n",
    "deadline = 230000\n",
    "after_limit = 200000\n",
    "\n",
    "for example in iterator:\n",
    "    count += 1\n",
    "    if count <= after_limit:\n",
    "        if count % breakline == 0:\n",
    "            print(count)\n",
    "        continue\n",
    "\n",
    "    if count % 100 == 0:\n",
    "        print(count, datetime.datetime.now())\n",
    "    \n",
    "    correct_sentence = example['wrong']\n",
    "    doc = nlp_cuv(correct_sentence)\n",
    "    list_of_words = [token for token in doc if not token.is_punct]\n",
    "    list_of_words_lemma = [token.lemma_ for token in doc if not token.is_punct]\n",
    "\n",
    "    word_count = len(list_of_words)\n",
    "\n",
    "    # list_of_words = [word['FORM'] for word in metadata if word['FEATS'] != '_']\n",
    "    if len(list_of_words) < 3:\n",
    "        continue\n",
    "        \n",
    "    nr_errs = number_of_words_changed(word_count)\n",
    "    numbers_to_be_changed = np.random.choice(np.arange(0, word_count), size=nr_errs, replace=False).tolist()\n",
    "\n",
    "    skip_flag = False\n",
    "    wrong_sentence = \"\"\n",
    "    nr_word = -1\n",
    "    for i in range(len(list_of_words)):\n",
    "      if skip_flag == True:\n",
    "        skip_flag = False\n",
    "        nr_word += 1\n",
    "        continue\n",
    "\n",
    "      word = list_of_words[i]\n",
    "      word_lemma = list_of_words_lemma[i]  \n",
    "        \n",
    "      if word in punctuation_list:\n",
    "        new_punctuation = punctuation_substitution(word.text)\n",
    "        if new_punctuation in ['-', ' ']:\n",
    "          wrong_sentence = copy_word(wrong_sentence, new_punctuation, False)\n",
    "        else:\n",
    "          wrong_sentence = copy_word(wrong_sentence, word.text)\n",
    "\n",
    "        continue\n",
    "\n",
    "      nr_word += 1\n",
    "\n",
    "      # Token not to be changed\n",
    "      if nr_word not in numbers_to_be_changed:\n",
    "        wrong_sentence = copy_word(wrong_sentence, word.text)\n",
    "        continue\n",
    "\n",
    "      # Type of error - Distribution of Probability\n",
    "      token_error_action = random.randint(1, 100) / 100\n",
    "\n",
    "      # CONCATENATION\n",
    "      if token_error_action <= 0.10 and i < len(list_of_words) - 1:\n",
    "        next_word = list_of_words[i + 1]\n",
    "        if str(next_word.morph) != '':\n",
    "          wrong_sentence = concatenate(wrong_sentence, word.text, next_word.text)\n",
    "          skip_flag = True\n",
    "          continue\n",
    "\n",
    "      # TRANSPOSITION\n",
    "      if token_error_action > 0.12 and token_error_action <= 0.2 and i < len(list_of_words) - 1:\n",
    "        next_word = list_of_words[i + 1]\n",
    "        if str(next_word.morph) != '':\n",
    "          wrong_sentence = transpose(wrong_sentence, word.text, next_word.text)\n",
    "          skip_flag = True\n",
    "          continue\n",
    "\n",
    "      # DELETION\n",
    "      if token_error_action > 0.2 and token_error_action <= 0.25:\n",
    "        continue\n",
    "\n",
    "      # MISSPELLING\n",
    "      if token_error_action > 0.25 and token_error_action <= 0.6:\n",
    "        wrong_sentence = copy_word(wrong_sentence, misspell(word.text))\n",
    "        continue\n",
    "\n",
    "      # SUBSTITUTION\n",
    "      if token_error_action > 0.6:\n",
    "        if word.pos_ in ['PROPN', 'NUM', 'SYM']:\n",
    "          wrong_sentence = copy_word(wrong_sentence, word.text)\n",
    "        else:\n",
    "          wrong_sentence = copy_word(wrong_sentence, substitute(word))\n",
    "        continue\n",
    "\n",
    "      # # DEFAULT\n",
    "      wrong_sentence = copy_word(wrong_sentence, word.text)\n",
    "\n",
    "    data.append({\"wrong\": wrong_sentence[1:], \"right\": correct_sentence})\n",
    "\n",
    "    if count % breakline == 0:\n",
    "      contor_file += 1\n",
    "      print(count, datetime.datetime.now(), contor_file)\n",
    "      save_data(data, contor_file)\n",
    "      data = []\n",
    "\n",
    "    if count == deadline:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if count % breakline == 0:\n",
    "      contor_file += 1\n",
    "      print(count, datetime.datetime.now(), contor_file)\n",
    "      save_data(data, contor_file)\n",
    "      data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
