{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EpaF-9x5-t_"
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install rowordnet\n",
    "!pip install phunspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_12MmtN8_N4v"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9489e403164ec188bc32bff8eb6ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import rowordnet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import phunspell\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "# 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\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v--JtrbxANfb"
   },
   "outputs": [],
   "source": [
    "wn = rowordnet.RoWordNet()\n",
    "pspell = phunspell.Phunspell('ro_RO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7KMgCyhE55L5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19effb802e9c423d87ca6e307bb88fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"mateiaassAI/MarcellP\", streaming = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IEZBuJ6OXrgT"
   },
   "outputs": [],
   "source": [
    "dictio_words = {1: {0: 0.0, 1: 0.3, 2: 1.01},\n",
    "          3: {1: 0.0, 2: 0.3, 3: 1.01},\n",
    "          6: {2: 0.0, 3: 0.1, 4: 0.75, 5: 1.01},\n",
    "          9: {3: 0.0, 4: 0.2, 5: 0.5, 6: 0.7, 7: 1.01},\n",
    "          16: {3: 0.0, 4: 0.1, 5: 0.3, 6: 0.4, 7: 0.8, 8: 1.01},\n",
    "          20: {4: 0.0, 5: 0.1, 6: 0.3, 7: 0.5, 8: 0.8, 9: 1.01},\n",
    "          30: {5: 0.0, 6: 0.1, 7: 0.3, 8: 0.5, 9: 0.8, 10: 1.01},\n",
    "          100000000: None}\n",
    "\n",
    "def number_of_words_changed(sentence_length):\n",
    "  prob = random.randint(1, 100) / 100\n",
    "  keys = list(dictio_words.keys())\n",
    "  little_dict = {}\n",
    "  for i in range(len(dictio_words) - 1):\n",
    "      if sentence_length >= keys[i] and sentence_length < keys[i+1]:\n",
    "          little_dict = dictio_words[keys[i]]\n",
    "          values = list(little_dict.values())\n",
    "          for j in range(len(values) - 1):\n",
    "              if prob >= values[j] and prob < values[j+1]:\n",
    "                  return list(little_dict.keys())[list(little_dict.values()).index(values[j])]\n",
    "\n",
    "dictio_spell = {1: {0: 0.0, 1: 1.01},\n",
    "          3: {1: 0.0, 2: 1.01},\n",
    "          5: {1: 0.0, 2: 0.3, 3: 1.01},\n",
    "          10: {1: 0.0, 2: 0.4, 3: 0.7, 4: 1.01},\n",
    "          100000000: None}\n",
    "\n",
    "def number_of_misspellings(word_length):\n",
    "  prob = random.randint(1, 100) / 100\n",
    "\n",
    "  keys = list(dictio_spell.keys())\n",
    "  little_dict = {}\n",
    "  for i in range(len(dictio_spell) - 1):\n",
    "      if word_length >= keys[i] and word_length < keys[i+1]:\n",
    "          little_dict = dictio_spell[keys[i]]\n",
    "          values = list(little_dict.values())\n",
    "          for j in range(len(values) - 1):\n",
    "              if prob >= values[j] and prob < values[j+1]:\n",
    "                  return list(little_dict.keys())[list(little_dict.values()).index(values[j])]\n",
    "\n",
    "mispell_replacement_candidates = {\n",
    "    'a': ['ea', 'ă', 'â', 'au', 'q', 'w', 's', 'z'],\n",
    "    'ă': ['e', 'â', 'a', 'p', 'î', 'ț', 'ș'],\n",
    "    'â': ['î', 'ă', 'a', 'ț'],\n",
    "    'b': ['v', 'd', 'p', 'v', 'g', 'h', 'n'],\n",
    "    'c': ['k', 'g', 'x', 'd', 'f', 'v'],\n",
    "    'd': ['b', 'p', 'e', 'r', 's', 'f', 'x', 'c'],\n",
    "    'e': ['ie', 'i', 'ă', 'ea', 'esc', 'w', 's', 'd', 'r'],\n",
    "    'f': ['r', 'g', 'd', 'c', 'v'],\n",
    "    'g': ['c', 't', 'h', 'f', 'v', 'b'],\n",
    "    'h': ['y', 'g', 'j', 'b', 'n'],\n",
    "    'i': ['ii', 'iii', 'e', 'î', 'y', 'ie', 'l', 'u', 'o', 'j', 'k'],\n",
    "    'î': ['â', 'i', 'ă', 'ț'],\n",
    "    'j': ['ș', 'u', 'h', 'k', 'n', 'm'],\n",
    "    'k': ['c', 'i', 'j', 'l', 'm'],\n",
    "    'l': ['n', 'i', 'o', 'p', 'k'],\n",
    "    'm': ['n', 'j', 'k'],\n",
    "    'n': ['m', 'l', 'j', 'h', 'b'],\n",
    "    'o': ['u', 'or', 'i', 'k', 'l', 'p'],\n",
    "    'p': ['q', 'b', 'd', 'o', 'l'],\n",
    "    'q': ['c', 'p', 'w', 'a'],\n",
    "    'r': ['e', 'd', 't', 'f'],\n",
    "    's': ['ș', 'z', 'w', 'a', 'd', 's', 'z'],\n",
    "    'ș': ['j', 's', 'ă', 'ț', 'p', 'l'],\n",
    "    't': ['ț', 'r', 'f', 'g', 'y'],\n",
    "    'ț': ['t', 'ă', 'â', 'ș', 'î'],\n",
    "    'u': ['v', 'o', 'y', 'h', 'j', 'i'],\n",
    "    'v': ['w', 'u', 'b', 'vr', 'c', 'f', 'g'],\n",
    "    'w': ['v', 'q', 'e', 'a', 's'],\n",
    "    'x': ['cs', 'gz', 'cș', 's', 'd', 'z', 'c'],\n",
    "    'y': ['i', 't', 'u', 'g', 'h'],\n",
    "    'z': ['s', 'a', 'x'],\n",
    "}\n",
    "\n",
    "diacritice_to_normal = {\n",
    "    'ă': ['a', 'â', 'â', 'a'],\n",
    "    'â' : ['a', 'ă', 'î', 'a'],\n",
    "    'î' : ['i', 'i', 'i', 'i'],\n",
    "    'ț' : ['t', 't', 't', 't'],\n",
    "    'ș' : ['s', 's', 's', 's']\n",
    "}\n",
    "\n",
    "normal_to_diacritice = {\n",
    "    'a' : ['ă', 'â', 'a', 'a'],\n",
    "    'i' : ['î', 'î', 'i', 'i'],\n",
    "    't' : ['ț', 'ț', 't', 't'],\n",
    "    's' : ['ș', 'ș', 's', 's']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cTfV5ukCbpFx"
   },
   "outputs": [],
   "source": [
    "punctuation_dict = {\n",
    "    ' ': {' ': 0.00, ',': 0.95, '.': 0.975, '-----': 1.01},\n",
    "    ',': {' ': 0.00, ',': 0.41, '.': 0.95, '-----': 1.01},\n",
    "    ';': {' ': 0.00, ',': 0.85, ';': 0.90, '-----': 1.01},\n",
    "    ':': {' ': 0.00, ',': 0.90, ':': 0.92, '-----': 1.01},\n",
    "    '-': {' ': 0.00, '-': 0.95, '-----': 1.01},\n",
    "    '.': {' ': 0.00, ';': 0.20, '.': 0.23, '...': 0.97, '-----': 1.01},\n",
    "    '?': {' ': 0.00, '.': 0.80, '?': 0.84, '!': 0.96, '-----': 1.01},\n",
    "    '!': {' ': 0.00, '.': 0.80, '?': 0.90, '!': 0.97, '-----': 1.01},\n",
    "    '...': {' ': 0.00, '...': 0.80, '-----': 1.01}\n",
    "  }\n",
    "\n",
    "def punctuation_substitution(letter):\n",
    "  prob = random.randint(1, 100) / 100\n",
    "  keys = list(punctuation_dict.keys())\n",
    "  little_dict = punctuation_dict[letter]\n",
    "  values = list(little_dict.values())\n",
    "  for j in range(len(values) - 1):\n",
    "    if prob >= values[j] and prob < values[j+1]:\n",
    "      return list(little_dict.keys())[list(little_dict.values()).index(values[j])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nY0_ga4pbg9U"
   },
   "outputs": [],
   "source": [
    "def copy_word(sentence, word, isSpace = True):\n",
    "  if isSpace:\n",
    "    sentence = sentence + \" \" + word\n",
    "  else:\n",
    "    sentence = sentence + word\n",
    "  return sentence\n",
    "\n",
    "def concatenate(sentence, word1, word2, isSpace = True):\n",
    "  if isSpace:\n",
    "    sentence = sentence + \" \" + word1 + word2\n",
    "  else:\n",
    "    sentence = sentence + word1 + word2\n",
    "  return sentence\n",
    "\n",
    "def transpose(sentence, word1, word2, isSpace = True):\n",
    "  if isSpace:\n",
    "    sentence = sentence + \" \" + word2 + \" \" + word1\n",
    "  else:\n",
    "    sentence = sentence + word2 + \" \" + word1\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pboKH9FYyXSO"
   },
   "outputs": [],
   "source": [
    "def noisy_diacritice(letter):\n",
    "    if letter in diacritice_to_normal.keys():\n",
    "        r_nr = random.randint(0, 3)\n",
    "        # print(letter, diacritice_to_normal[letter][r_nr])\n",
    "        return diacritice_to_normal[letter][r_nr]\n",
    "    elif letter in normal_to_diacritice.keys():\n",
    "        r_nr = random.randint(0, 3)\n",
    "        return normal_to_diacritice[letter][r_nr]\n",
    "        # print(letter, normal_to_diacritice[letter][r_nr])\n",
    "    return letter\n",
    "\n",
    "def copy_letter(word, letter):\n",
    "    if letter is None:\n",
    "        letter = ''\n",
    "    return word + noisy_diacritice(letter)\n",
    "    \n",
    "def transpose_letters(word, letter1, letter2):\n",
    "    if letter2 is None:\n",
    "        letter2 = ''\n",
    "    return word + noisy_diacritice(letter2) + letter1\n",
    "\n",
    "def replace_letter(word, letter):\n",
    "    if letter is None:\n",
    "        letter = ''\n",
    "    return word + noisy_diacritice(letter)\n",
    "    \n",
    "def insert_letter(word, letter, new_letter):\n",
    "    if letter is None:\n",
    "        letter = ''\n",
    "    return word + noisy_diacritice(letter) + new_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "APZfrT8BvA2o"
   },
   "outputs": [],
   "source": [
    "alphabet = \"аăâbcdefghiîjklmnopqrsștțuvwxyz\"\n",
    "alphabet2 = \"аăâbcdefghiîjklmnopqrsștțuvwxyz----\"\n",
    "noisy_letter = \"-._&@(){}`\\';--,\\\":\"\n",
    "\n",
    "def misspell(word):\n",
    "  number_of_changed_letters = number_of_misspellings(len(word))\n",
    "  letters_to_be_changed = np.random.choice(np.arange(0, len(word)), size=number_of_changed_letters, replace=False).tolist()\n",
    "  wrong_word = \"\"\n",
    "  skip_flag = False\n",
    "  for i in range(len(word)):\n",
    "    if skip_flag == True:\n",
    "      skip_flag = False\n",
    "      continue\n",
    "    letter = word[i]\n",
    "\n",
    "    # Letter not to be changed\n",
    "    if i not in letters_to_be_changed:\n",
    "      wrong_word = copy_letter(wrong_word, letter)\n",
    "      continue\n",
    "\n",
    "    # Type of misspelling - Distribution of Probability\n",
    "    letter_error_action = random.randint(1, 100) / 100\n",
    "\n",
    "    # DELETION\n",
    "    if letter_error_action <= 0.25:\n",
    "      continue\n",
    "\n",
    "    # INSERTION\n",
    "    if letter_error_action > 0.25 and letter_error_action <= 0.45:\n",
    "      alphabet_letter = alphabet2[random.randint(0, len(alphabet2) - 1)]\n",
    "      wrong_word = insert_letter(wrong_word, letter, alphabet_letter)          \n",
    "      continue\n",
    "\n",
    "    if letter_error_action % 0.2 > 0.12:\n",
    "        wrong_word = copy_letter(wrong_word, noisy_letter[random.randint(0, len(noisy_letter) -1)])          \n",
    "\n",
    "    # TRANSPOSITION\n",
    "    if letter_error_action > 0.35 and letter_error_action <= 0.65 and i < len(word) - 1:\n",
    "      next_letter = word[i + 1]\n",
    "      wrong_word = transpose_letters(wrong_word, letter, next_letter)\n",
    "      skip_flag = True\n",
    "      continue\n",
    "\n",
    "    # REPLACEMENT\n",
    "    if letter_error_action > 0.60:\n",
    "      if letter.lower() not in alphabet:\n",
    "        alphabet_letter = letter\n",
    "      else:\n",
    "        # if letter_error_action <= 0.68 and i == 0:\n",
    "        #   alphabet_letter = letter.lower() if letter.islower() else letter.upper()\n",
    "\n",
    "        if letter_error_action <= 0.7 and i == len(word) - 1 and letter.lower() in ['a', 'i', 'l']:\n",
    "          continue\n",
    "\n",
    "        if letter_error_action > 0.90:\n",
    "          alphabet_letter = alphabet[random.randint(0, len(alphabet) - 1)]\n",
    "        else:\n",
    "            alphabet_letter = random.choice(mispell_replacement_candidates[letter.lower()])\n",
    "\n",
    "      wrong_word = replace_letter(wrong_word, alphabet_letter)\n",
    "      continue\n",
    "\n",
    "    # DEFAULT\n",
    "    wrong_word = copy_letter(wrong_word, letter)\n",
    "\n",
    "  return wrong_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PcO7ZeN3xlWW"
   },
   "outputs": [],
   "source": [
    "def morphologic_dex(word):\n",
    "  if len(word) <= 3:\n",
    "    return word\n",
    "\n",
    "  url = f'https://dexonline.ro/definitie/{word}/paradigma'\n",
    "  response = requests.get(url)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    action = random.randint(1, 100) / 100\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    if action < 0.7:\n",
    "        para_lexemes = soup.find_all('div', class_='paraLexeme')\n",
    "    \n",
    "        for para_lexeme in para_lexemes:\n",
    "          lexeme_name = para_lexeme.find('span', class_='lexemeName').text\n",
    "          if lexeme_name == word:\n",
    "            table = para_lexeme.find('table', class_='lexeme')\n",
    "    \n",
    "            if table:\n",
    "              unique_cells = set()\n",
    "              form_cells = table.find_all('td', class_='form')\n",
    "    \n",
    "              for cell in form_cells:\n",
    "                if not cell.find(class_='elisionHidden') and not cell.find(class_='notRecommendedHidden'):\n",
    "                  text = cell.get_text(strip=True)\n",
    "                  if '—' not in text:\n",
    "                    text = text.replace(')', ' ').replace('(', '')\n",
    "                    unique_cells.add(text)\n",
    "    \n",
    "              if unique_cells:\n",
    "                random_word = random.choice(list(unique_cells))\n",
    "                return random_word\n",
    "                # return unique_cells\n",
    "    else:\n",
    "        spans_synonyms = soup.find_all('span', class_='badge-relation badge-relation-1')\n",
    "        unique_cells = set()\n",
    "\n",
    "        for spans in spans_synonyms:\n",
    "            text = spans.text.replace('\\'', ' ').replace(' ', '')\n",
    "            unique_cells.add(text)\n",
    "\n",
    "        if unique_cells:\n",
    "            return random.choice(list(unique_cells))\n",
    "        # return unique_cells\n",
    "  return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c9GUbngn7ttP"
   },
   "outputs": [],
   "source": [
    "lista_conjunctii = ['și', 'dar', 'iar', 'că', 'să', 'ci', 'fie', 'sau', 'ori', 'ci și', 'ca să', 'încât să', 'nici', 'însă', 'ba', 'deci', 'așadar', 'totuși', 'însăși', 'chiar', 'tot', 'încă', 'atât', 'pe când', 'în timp ce',\n",
    "                    'cu toate că', 'întrucât', 'precum', 'totodată', 'care', 'pe care']\n",
    "\n",
    "lista_prepozitii = ['la', 'în', 'către', 'contrar', 'fără', 'după', 'cu', 'lângă', 'asupra', 'de', 'de la', 'despre', 'dimprejurul', 'din', 'dinaintea', 'înspre', 'între', 'înăuntrul', 'împotriva', 'împrejurul', 'înaintea',\n",
    "                    'înapoia', 'întru', 'dedesubtul', 'datorită', 'printre', 'prin', 'primprejur', 'peste', 'pentru', 'pe', 'până', 'via', 'spre', 'sub', 'din cauza', 'din pricina', 'în vederea', 'cu excepția', 'cu tot cu', 'a']\n",
    "\n",
    "lista_articole_posesive = ['a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor']\n",
    "lista_articole_demonstrative = ['cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor', 'cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor', 'cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor', 'cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor']\n",
    "lista_articole_nehotarate = ['un', 'o', 'niste', 'unor', 'unui', 'unei', 'un', 'o', 'niste', 'unor', 'unui', 'unei', 'un', 'o', 'niste', 'unor', 'unui', 'unei','un', 'o', 'niste', 'unor', 'unui', 'unei']\n",
    "\n",
    "def substitute(word_metadata):\n",
    "  action = random.randint(1, 100) / 100\n",
    "\n",
    "  if len(word_metadata['FORM']) > 8 and action > 0.6:\n",
    "    action = 0.5\n",
    "\n",
    "  # RoWORDNET\n",
    "  if action <= 0.2:\n",
    "    word = word_metadata['LEMMA'].lower()\n",
    "    syn_list = []\n",
    "    synset_ids = wn.synsets(literal=word)\n",
    "    for s in synset_ids:\n",
    "      if word in wn.synset(s).literals:\n",
    "        for literal in wn.synset(s).literals:\n",
    "          if literal != word and literal not in syn_list:\n",
    "            syn_list.append(literal)\n",
    "    if len(syn_list) > 0:\n",
    "      return random.choice(syn_list)\n",
    "    else:\n",
    "      return word_metadata['FORM']\n",
    "\n",
    "  # DEXONLINE\n",
    "  elif action > 0.2 and action <= 0.7:\n",
    "\n",
    "    if word_metadata['UPOS'] == 'CONJ' and action <= 0.3:\n",
    "      return random.choice(lista_conjunctii)\n",
    "\n",
    "    if word_metadata['UPOS'] == 'ADP' and action <= 0.3:\n",
    "      return random.choice(lista_prepozitii)\n",
    "\n",
    "    if word_metadata['UPOS'] == 'DET' and word_metadata['FORM'] in lista_articole_posesive and action <= 0.3:\n",
    "      return random.choice(lista_articole_posesive)\n",
    "    if word_metadata['UPOS'] == 'DET' and word_metadata['FORM'] in lista_articole_demonstrative and action <= 0.3:\n",
    "      return random.choice(lista_articole_demonstrative)\n",
    "\n",
    "    if word_metadata['UPOS'] == 'DET' and word_metadata['FORM'] in lista_articole_nehotarate and action <= 0.3:\n",
    "      return random.choice(lista_articole_nehotarate)\n",
    "    return morphologic_dex(word_metadata['LEMMA'])\n",
    "\n",
    "  # SPELLCHECKER\n",
    "  elif action > 0.7:\n",
    "    sugestions = list(pspell.suggest(word_metadata['FORM']))\n",
    "    if len(sugestions) == 0:\n",
    "      return morphologic_dex(word_metadata['LEMMA'])\n",
    "    return random.choice(sugestions)\n",
    "\n",
    "  return word_metadata['FORM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4YRo4YmSGLOy"
   },
   "outputs": [],
   "source": [
    "def save_data(data, counter):\n",
    "  output_file = f'MEID/{counter}.jsonl'\n",
    "  with open(output_file, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    for example_parsed in data:\n",
    "      json.dump(example_parsed, json_file, ensure_ascii=False)#, indent=4)\n",
    "      json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pqr52hP3TGBU",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "61000 2024-09-12 13:00:40.420346\n",
      "62000 2024-09-12 13:10:24.623757\n",
      "63000 2024-09-12 13:19:23.403666\n",
      "64000 2024-09-12 13:27:20.075469\n",
      "65000 2024-09-12 13:32:26.065097\n",
      "66000 2024-09-12 13:33:22.693931\n",
      "67000 2024-09-12 13:36:48.459855\n",
      "68000 2024-09-12 13:47:22.002773\n",
      "69000 2024-09-12 13:56:26.514473\n",
      "70000 2024-09-12 14:05:44.994829\n",
      "70000 2024-09-12 14:05:45.958673 9\n",
      "71000 2024-09-12 14:15:22.030217\n",
      "72000 2024-09-12 14:20:16.936109\n",
      "73000 2024-09-12 14:24:27.102186\n",
      "74000 2024-09-12 14:32:03.899672\n",
      "75000 2024-09-12 14:39:44.171470\n",
      "76000 2024-09-12 14:48:19.406267\n",
      "77000 2024-09-12 14:57:04.944706\n",
      "78000 2024-09-12 15:05:30.116165\n",
      "79000 2024-09-12 15:13:40.038512\n",
      "80000 2024-09-12 15:19:44.767439\n",
      "80000 2024-09-12 15:19:45.279093 10\n",
      "81000 2024-09-12 15:26:39.228177\n",
      "82000 2024-09-12 15:32:53.965778\n",
      "83000 2024-09-12 15:40:40.877089\n",
      "84000 2024-09-12 15:47:32.706537\n",
      "85000 2024-09-12 15:55:14.565097\n",
      "85000 2024-09-12 15:55:14.667271 11\n",
      "86000 2024-09-12 16:02:17.727839\n",
      "87000 2024-09-12 16:12:32.716178\n",
      "88000 2024-09-12 16:20:33.231884\n",
      "89000 2024-09-12 16:28:47.014830\n",
      "90000 2024-09-12 16:37:39.735599\n",
      "90000 2024-09-12 16:37:40.190360 12\n",
      "91000 2024-09-12 16:43:09.818859\n",
      "92000 2024-09-12 16:52:19.476101\n",
      "93000 2024-09-12 16:56:25.115225\n",
      "94000 2024-09-12 17:06:45.013009\n",
      "95000 2024-09-12 17:15:26.493769\n",
      "95000 2024-09-12 17:15:27.023394 13\n",
      "96000 2024-09-12 17:23:28.041041\n",
      "97000 2024-09-12 17:30:37.531395\n",
      "98000 2024-09-12 17:38:43.919672\n",
      "99000 2024-09-12 17:46:27.749482\n",
      "100000 2024-09-12 17:53:28.270881\n",
      "100000 2024-09-12 17:53:28.427211 14\n",
      "101000 2024-09-12 17:59:24.311050\n",
      "102000 2024-09-12 18:05:24.420712\n",
      "103000 2024-09-12 18:14:02.269359\n",
      "104000 2024-09-12 18:23:50.466333\n",
      "105000 2024-09-12 18:32:22.640427\n",
      "105000 2024-09-12 18:32:23.363596 15\n",
      "106000 2024-09-12 18:43:00.836941\n",
      "107000 2024-09-12 18:53:17.483356\n",
      "108000 2024-09-12 19:01:17.290312\n",
      "109000 2024-09-12 19:09:42.687890\n",
      "110000 2024-09-12 19:18:19.282273\n",
      "110000 2024-09-12 19:18:20.530882 16\n",
      "111000 2024-09-12 19:26:52.095336\n",
      "112000 2024-09-12 19:36:35.356526\n",
      "113000 2024-09-12 19:47:07.751890\n",
      "114000 2024-09-12 19:56:21.329450\n",
      "115000 2024-09-12 20:05:14.637265\n",
      "115000 2024-09-12 20:05:15.120426 17\n",
      "116000 2024-09-12 20:13:38.720230\n",
      "117000 2024-09-12 20:18:11.195357\n",
      "118000 2024-09-12 20:23:15.639230\n",
      "119000 2024-09-12 20:31:45.872752\n",
      "120000 2024-09-12 20:41:13.269242\n",
      "120000 2024-09-12 20:41:14.690084 18\n",
      "121000 2024-09-12 20:50:03.148212\n",
      "122000 2024-09-12 20:59:44.931586\n",
      "123000 2024-09-12 21:10:05.920038\n",
      "124000 2024-09-12 21:18:30.938868\n",
      "125000 2024-09-12 21:26:48.584787\n",
      "125000 2024-09-12 21:26:49.570902 19\n",
      "126000 2024-09-12 21:36:37.694198\n",
      "127000 2024-09-12 21:45:43.938727\n",
      "128000 2024-09-12 21:55:00.837689\n",
      "129000 2024-09-12 22:03:26.187194\n",
      "130000 2024-09-12 22:13:02.578279\n",
      "130000 2024-09-12 22:13:03.209585 20\n",
      "131000 2024-09-12 22:21:28.147691\n",
      "132000 2024-09-12 22:31:16.970184\n",
      "133000 2024-09-12 22:39:21.415444\n",
      "134000 2024-09-12 22:48:14.567087\n",
      "135000 2024-09-12 22:58:05.029945\n",
      "135000 2024-09-12 22:58:05.029945 21\n",
      "136000 2024-09-12 23:01:15.871257\n",
      "137000 2024-09-12 23:10:36.649634\n",
      "138000 2024-09-12 23:20:48.121146\n",
      "139000 2024-09-12 23:31:29.572469\n",
      "140000 2024-09-12 23:40:28.993243\n",
      "140000 2024-09-12 23:40:28.993762 22\n",
      "141000 2024-09-12 23:49:07.140386\n",
      "142000 2024-09-12 23:58:32.556228\n",
      "143000 2024-09-13 00:08:28.114849\n",
      "144000 2024-09-13 00:15:32.820083\n",
      "145000 2024-09-13 00:24:23.833298\n",
      "145000 2024-09-13 00:24:25.707325 23\n",
      "146000 2024-09-13 00:34:23.712645\n",
      "147000 2024-09-13 00:43:50.446852\n",
      "148000 2024-09-13 00:52:41.507654\n",
      "149000 2024-09-13 01:04:07.314469\n",
      "150000 2024-09-13 01:15:03.081023\n",
      "150000 2024-09-13 01:15:03.454129 24\n",
      "151000 2024-09-13 01:25:06.012595\n",
      "152000 2024-09-13 01:33:28.048024\n",
      "153000 2024-09-13 01:41:10.352691\n",
      "154000 2024-09-13 01:51:15.632463\n",
      "155000 2024-09-13 02:00:28.222417\n",
      "155000 2024-09-13 02:00:29.249117 25\n",
      "156000 2024-09-13 02:10:37.359087\n",
      "157000 2024-09-13 02:17:31.569304\n",
      "158000 2024-09-13 02:25:25.205737\n",
      "159000 2024-09-13 02:34:47.544681\n",
      "160000 2024-09-13 02:45:02.592788\n",
      "160000 2024-09-13 02:45:03.208348 26\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset[\"train\"])\n",
    "count = 0\n",
    "data = []\n",
    "\n",
    "punctuation_list = [' ', ',', ';', ':', '-', '.', '?', '!', '...']\n",
    "\n",
    "contor_file = 8\n",
    "breakline = 5000\n",
    "deadline = 160000\n",
    "after_limit = 60000\n",
    "\n",
    "for example in iterator:\n",
    "    count += 1\n",
    "    if count <= after_limit:\n",
    "        if count % breakline == 0:\n",
    "            print(count)\n",
    "        continue\n",
    "\n",
    "    if count % 1000 == 0:\n",
    "        print(count, datetime.datetime.now())\n",
    "    \n",
    "    correct_sentence = example['text']\n",
    "    metadata = example['metadata_text']\n",
    "\n",
    "    list_of_words = [word['FORM'] for word in metadata if word['FEATS'] != '_']\n",
    "\n",
    "    word_count = len(list_of_words)\n",
    "    if word_count <= 3:\n",
    "        continue\n",
    "        \n",
    "    nr_errs = number_of_words_changed(word_count)\n",
    "    numbers_to_be_changed = np.random.choice(np.arange(0, word_count), size=nr_errs, replace=False).tolist()\n",
    "\n",
    "    skip_flag = False\n",
    "    wrong_sentence = \"\"\n",
    "    nr_word = -1\n",
    "    for i in range(len(metadata)):\n",
    "      if skip_flag == True:\n",
    "        skip_flag = False\n",
    "        nr_word += 1\n",
    "        continue\n",
    "\n",
    "      word = metadata[i]\n",
    "      if word['FEATS'] == '_':\n",
    "        if word['FORM'] in punctuation_list:\n",
    "          new_punctuation = punctuation_substitution(word['FORM'])\n",
    "          if new_punctuation in ['-', ' ']:\n",
    "            wrong_sentence = copy_word(wrong_sentence, new_punctuation, False)\n",
    "        else:\n",
    "          wrong_sentence = copy_word(wrong_sentence, word['FORM'])\n",
    "\n",
    "        continue\n",
    "\n",
    "      nr_word += 1\n",
    "\n",
    "      # Token not to be changed\n",
    "      if nr_word not in numbers_to_be_changed:\n",
    "        wrong_sentence = copy_word(wrong_sentence, word['FORM'])\n",
    "        continue\n",
    "\n",
    "      # Type of error - Distribution of Probability\n",
    "      token_error_action = random.randint(1, 100) / 100\n",
    "\n",
    "      # CONCATENATION\n",
    "      if token_error_action <= 0.10 and i < len(metadata) - 1:\n",
    "        next_word = metadata[i + 1]\n",
    "        if next_word['FEATS'] != '_':\n",
    "          wrong_sentence = concatenate(wrong_sentence, word['FORM'], next_word['FORM'])\n",
    "          skip_flag = True\n",
    "          continue\n",
    "\n",
    "      # TRANSPOSITION\n",
    "      if token_error_action > 0.12 and token_error_action <= 0.2 and i < len(metadata) - 1:\n",
    "        next_word = metadata[i + 1]\n",
    "        if next_word['FEATS'] != '_':\n",
    "          wrong_sentence = transpose(wrong_sentence, word['FORM'], next_word['FORM'])\n",
    "          skip_flag = True\n",
    "          continue\n",
    "\n",
    "      # DELETION\n",
    "      if token_error_action > 0.2 and token_error_action <= 0.25:\n",
    "        continue\n",
    "\n",
    "      # MISSPELLING\n",
    "      if token_error_action > 0.25 and token_error_action <= 0.6:\n",
    "        wrong_sentence = copy_word(wrong_sentence, misspell(word['FORM']))\n",
    "        continue\n",
    "\n",
    "      # SUBSTITUTION\n",
    "      if token_error_action > 0.6:\n",
    "        if word['UPOS'] in ['PROPN', 'NUM', 'SYM']:\n",
    "          wrong_sentence = copy_word(wrong_sentence, word['FORM'])\n",
    "        else:\n",
    "          wrong_sentence = copy_word(wrong_sentence, substitute(word))\n",
    "        continue\n",
    "\n",
    "      # DEFAULT\n",
    "      wrong_sentence = copy_word(wrong_sentence, word['FORM'])\n",
    "\n",
    "    data.append({\"wrong\": wrong_sentence[1:], \"right\": correct_sentence})\n",
    "\n",
    "    if count % breakline == 0:\n",
    "      contor_file += 1\n",
    "      print(count, datetime.datetime.now(), contor_file)\n",
    "      save_data(data, contor_file)\n",
    "      data = []\n",
    "\n",
    "    if count == deadline:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
