{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1902ae-aa66-4660-82cc-25e8df6e7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c252e5-8ad9-4ddb-8669-a9be26bfcdf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_columns(data):\n",
    "    lines = data.strip().split('\\n')\n",
    "    columns = lines[0].split('=')[1].strip().split()\n",
    "    return columns\n",
    "\n",
    "def parse_metadata(data, filename):\n",
    "    lines = data.strip().split('\\n')\n",
    "\n",
    "    if len(lines) < 7:\n",
    "        return -1;\n",
    "        \n",
    "    metadata_dict = {}\n",
    "    metadata_dict['document_id'] = lines[1].split('=')[1].strip()\n",
    "    metadata_dict['eurovoc'] = lines[2].split('=')[1].strip().split()\n",
    "    metadata_dict['title'] = lines[3].split('=')[1].strip()\n",
    "    metadata_dict['date'] = lines[4].split('=')[1].strip()\n",
    "    metadata_dict['doctype'] = lines[5].split('=')[1].strip()\n",
    "    metadata_dict['url'] = lines[6].split('=')[1].strip()\n",
    "    metadata_dict['language'] = lines[7].split('=')[1].strip()\n",
    "    metadata_dict['filename'] = filename\n",
    "    return metadata_dict\n",
    "\n",
    "def parse_data_file(data, columns):\n",
    "    lines = data.strip().split('\\n')\n",
    "    sentences = re.split(r'# sent_id = .*?\\n# text = ', data.strip())\n",
    "    sentences.pop(0)\n",
    "\n",
    "    result_text = []\n",
    "    for sentence in sentences:\n",
    "        lines = sentence.split('\\n')\n",
    "\n",
    "        text = lines[0];\n",
    "\n",
    "        if len(text) < 10:\n",
    "            continue;\n",
    "        \n",
    "        result_dict = {}\n",
    "        metadata_sentence = []\n",
    "\n",
    "        for line in lines[1:]:\n",
    "            cols = line.strip().split('\\t')\n",
    "            if len(cols) < 10:\n",
    "                continue;\n",
    "                \n",
    "            tokens = {\n",
    "            \"ID\": cols[0],\n",
    "            \"FORM\": cols[1],\n",
    "            \"LEMMA\": cols[2],\n",
    "            \"UPOS\": cols[3],\n",
    "            \"XPOS\": cols[4],\n",
    "            \"FEATS\": cols[5],\n",
    "            \"HEAD\": cols[6],\n",
    "            \"DEPREL\": cols[7],\n",
    "            \"DEPS\": cols[8],\n",
    "            \"MISC\": cols[9]\n",
    "            }\n",
    "            \n",
    "            metadata_sentence.append(tokens)\n",
    "            \n",
    "        if len(metadata_sentence) < 5:\n",
    "            continue;\n",
    "            \n",
    "        result_dict['text'] = text;\n",
    "        result_dict['metadata_text'] = metadata_sentence\n",
    "        result_text.append(result_dict)\n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f199415-6d6b-4d62-a565-f3bb0c58dd32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed data saved to ro-parsed-single/104180.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_name = 'ro-annotated/mj_00000G000BRZ93RU63D3NY0STH13Q23L.conllup'\n",
    "with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "    columns = find_columns(data);\n",
    "\n",
    "directory = 'ro-annotated/'\n",
    "parsed_data = []\n",
    "\n",
    "i = 0;\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = file.read()\n",
    "    \n",
    "    metadata = parse_metadata(data, filename)\n",
    "\n",
    "    if metadata == -1:\n",
    "        continue;\n",
    "\n",
    "    if int(metadata[\"date\"]) < 2007:\n",
    "        continue;\n",
    "        \n",
    "    parsed_text = parse_data_file(data, columns)\n",
    "        \n",
    "    # final_dict = {}\n",
    "    # final_dict['metadata'] = metadata;\n",
    "    # final_dict['parsed_text'] = parsed_text;\n",
    "        \n",
    "    # parsed_data.append(final_dict)\n",
    "    i += 1\n",
    "      \n",
    "    # if i % 1 == 0:\n",
    "    # output_file = filename.replace(\".conllup\", \".json\")\n",
    "    output_file = f'ro-parsed-single/{i}.jsonl'\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        for example_parsed in parsed_text:\n",
    "            json.dump(example_parsed, json_file, ensure_ascii=False)#, indent=4)\n",
    "            json_file.write('\\n')\n",
    "        # parsed_data = []\n",
    "\n",
    "# output_file = filename.replace(\".conllup\", \".json\")\n",
    "# output_file = f'ro-parsed/{output_file}.json'\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    # json.dump(parsed_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Parsed data saved to\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "126b104b-af1c-444a-bd24-5ea117c4c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def jsonl_files_to_dataframe(directory_path):\n",
    "    data = []\n",
    "    i = 0;\n",
    "    j = 0;\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        jsonl_file_path = os.path.join(directory_path, file_name)\n",
    "        with open(jsonl_file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data.append(pd.read_json(StringIO(line), lines=True))\n",
    "        i += 1\n",
    "        if i == 1000:\n",
    "            i = 0\n",
    "            j += 1\n",
    "            df = pd.concat(data, ignore_index=True)\n",
    "            table = pa.Table.from_pandas(df);\n",
    "            pq.write_table(table, f'./ro-parsed-parquet/{j}.parquet')\n",
    "            data = []\n",
    "    \n",
    "    # return df\n",
    "\n",
    "directory_path = './ro-parsed-single/'\n",
    "jsonl_files_to_dataframe(directory_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
