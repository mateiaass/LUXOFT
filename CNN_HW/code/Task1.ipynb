{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d151357-37e8-476d-8147-5628bc8a5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from functools import partial\n",
    "\n",
    "from conv import MyConvStub, MyFilterStub\n",
    "from blur_kernel import get_blur_kernel\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "kernel_size_stub_constructor = partial(MyConvStub, input_channels=128, output_channels=128, num_groups=1, stride=1, dilation=1, bias=False)\n",
    "filter_size_stub_constructor = partial(MyConvStub, kernel_size=(3, 3), num_groups=1, stride=1, dilation=1, bias=False)\n",
    "biased_filter_size_stub_constructor = partial(MyConvStub, kernel_size=(3, 3), num_groups=1, stride=1, dilation=1, bias=True)\n",
    "stride_size_stub_constructor = partial(MyConvStub, input_channels=128, output_channels=128, kernel_size=(3, 3), num_groups=1, dilation=1, bias=False)\n",
    "dilation_size_stub_constructor = partial(MyConvStub, input_channels=128, output_channels=128, kernel_size=(3, 3), num_groups=1, stride=1, bias=False)\n",
    "groups_size_stub_constructor = partial(MyConvStub, input_channels=128, output_channels=256, kernel_size=(3, 3), stride=1, dilation=1, bias=False)\n",
    "\n",
    "\n",
    "ATOL = 1e-3\n",
    "\n",
    "class ConvTests(unittest.TestCase):\n",
    "    \"\"\"A suite of test that performs numerical checking on ConvStub\"\"\"\n",
    "    def test_square_kernels(self):\n",
    "        kernel_sizes = [(k, k) for k in range(1, 8)]\n",
    "        for kernel_size in kernel_sizes:\n",
    "            # create a conv stub\n",
    "            conv = kernel_size_stub_constructor(kernel_size=kernel_size)\n",
    "            random_input = torch.randn(4, 128, 64, 64)\n",
    "\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = F.conv2d(\n",
    "                input=random_input,\n",
    "                weight=conv.weight,\n",
    "                groups=conv.groups,\n",
    "                stride=conv.stride,\n",
    "                dilation=conv.dilation,\n",
    "                padding=0,\n",
    "            )\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n",
    "    def test_horizontal_kernel(self):\n",
    "        kernel_sizes = [(k, k + 2) for k in range(1, 8)]\n",
    "        for kernel_size in kernel_sizes:\n",
    "            # create a conv stub\n",
    "            conv = kernel_size_stub_constructor(kernel_size=kernel_size)\n",
    "            random_input = torch.randn(4, 128, 64, 64)\n",
    "\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = F.conv2d(\n",
    "                input=random_input,\n",
    "                weight=conv.weight,\n",
    "                groups=conv.groups,\n",
    "                stride=conv.stride,\n",
    "                dilation=conv.dilation,\n",
    "                padding=0,\n",
    "            )\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n",
    "    def test_vertical_kernel(self):\n",
    "        kernel_sizes = [(k + 2, k) for k in range(1, 8)]\n",
    "        for kernel_size in kernel_sizes:\n",
    "            # create a conv stub\n",
    "            conv = kernel_size_stub_constructor(kernel_size=kernel_size)\n",
    "            random_input = torch.randn(4, 128, 64, 64)\n",
    "\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = F.conv2d(\n",
    "                input=random_input,\n",
    "                weight=conv.weight,\n",
    "                groups=conv.groups,\n",
    "                stride=conv.stride,\n",
    "                dilation=conv.dilation,\n",
    "                padding=0,\n",
    "            )\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n",
    "    def test_increasing_filter_sizes(self):\n",
    "        input_sizes = [(2 ** i) for i in range(0, 8)]\n",
    "        output_sizes = [(3 ** i) for i in range(1, 6)]\n",
    "        for input_size, output_size in zip(input_sizes, output_sizes):\n",
    "            # create a conv stub\n",
    "            conv = filter_size_stub_constructor(input_channels=input_size, output_channels=output_size)\n",
    "            random_input = torch.randn(4, input_size, 64, 64)\n",
    "\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = F.conv2d(\n",
    "                input=random_input,\n",
    "                weight=conv.weight,\n",
    "                groups=conv.groups,\n",
    "                stride=conv.stride,\n",
    "                dilation=conv.dilation,\n",
    "                padding=0,\n",
    "            )\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n",
    "    def test_decreasing_filter_sizes(self):\n",
    "        output_sizes = [(2 ** i) for i in range(0, 8)]\n",
    "        input_sizes = [(3 ** i) for i in range(1, 6)]\n",
    "        for input_size, output_size in zip(input_sizes, output_sizes):\n",
    "            # create a conv stub\n",
    "            conv = filter_size_stub_constructor(input_channels=input_size, output_channels=output_size)\n",
    "            random_input = torch.randn(4, input_size, 64, 64)\n",
    "\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = F.conv2d(\n",
    "                input=random_input,\n",
    "                weight=conv.weight,\n",
    "                groups=conv.groups,\n",
    "                stride=conv.stride,\n",
    "                dilation=conv.dilation,\n",
    "                padding=0,\n",
    "            )\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n",
    "    def test_same_number_of_filters(self):\n",
    "        input_sizes = [(2 ** i) for i in range(0, 8)]\n",
    "        output_sizes = [(2 ** i) for i in range(0, 8)]\n",
    "        for input_size, output_size in zip(input_sizes, output_sizes):\n",
    "            # create a conv stub\n",
    "            conv = filter_size_stub_constructor(input_channels=input_size, output_channels=output_size)\n",
    "            random_input = torch.randn(4, input_size, 64, 64)\n",
    "\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = F.conv2d(\n",
    "                input=random_input,\n",
    "                weight=conv.weight,\n",
    "                groups=conv.groups,\n",
    "                stride=conv.stride,\n",
    "                dilation=conv.dilation,\n",
    "                padding=0,\n",
    "            )\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n",
    "    def test_stride(self):\n",
    "        strides = list(range(1, 4))\n",
    "        for stride in strides:\n",
    "            # create a conv stub\n",
    "            conv = stride_size_stub_constructor(stride=stride)\n",
    "            random_input = torch.randn(4, 128, 64, 64)\n",
    "\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = F.conv2d(\n",
    "                input=random_input,\n",
    "                weight=conv.weight,\n",
    "                groups=conv.groups,\n",
    "                stride=conv.stride,\n",
    "                dilation=conv.dilation,\n",
    "                padding=0\n",
    "            )\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n",
    "    def test_dilation(self):\n",
    "        dilations = list(range(1, 4))\n",
    "        for dilation in dilations:\n",
    "            # create a conv stub\n",
    "            conv = dilation_size_stub_constructor(dilation=dilation)\n",
    "            random_input = torch.randn(4, 128, 64, 64)\n",
    "\n",
    "            print(dilation)\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = F.conv2d(\n",
    "                input=random_input,\n",
    "                weight=conv.weight,\n",
    "                groups=conv.groups,\n",
    "                stride=conv.stride,\n",
    "                dilation=conv.dilation,\n",
    "                padding=0\n",
    "            )\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n",
    "    def test_grouping(self):\n",
    "        groups = [4, 8, 16, 32, 64]\n",
    "        for group in groups:\n",
    "            # create a conv stub\n",
    "            conv = groups_size_stub_constructor(num_groups=group)\n",
    "            random_input = torch.randn(4, 128, 64, 64)\n",
    "\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = F.conv2d(\n",
    "                input=random_input,\n",
    "                weight=conv.weight,\n",
    "                groups=conv.groups,\n",
    "                stride=conv.stride,\n",
    "                dilation=conv.dilation,\n",
    "                padding=0\n",
    "            )\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n",
    "    def test_biased_conv(self):\n",
    "        input_sizes = [(2 ** i) for i in range(0, 8)]\n",
    "        output_sizes = [(3 ** i) for i in range(1, 6)]\n",
    "        for input_size, output_size in zip(input_sizes, output_sizes):\n",
    "            # create a conv stub\n",
    "            conv = biased_filter_size_stub_constructor(input_channels=input_size, output_channels=output_size)\n",
    "            random_input = torch.randn(4, input_size, 64, 64)\n",
    "\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = F.conv2d(\n",
    "                input=random_input,\n",
    "                weight=conv.weight,\n",
    "                groups=conv.groups,\n",
    "                stride=conv.stride,\n",
    "                dilation=conv.dilation,\n",
    "                bias=conv.bias,\n",
    "                padding=0,\n",
    "            )\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n",
    "    def test_zero_biased_conv(self):\n",
    "        input_sizes = [(2 ** i) for i in range(0, 8)]\n",
    "        output_sizes = [(3 ** i) for i in range(1, 6)]\n",
    "        for input_size, output_size in zip(input_sizes, output_sizes):\n",
    "            # create a conv stub\n",
    "            conv = filter_size_stub_constructor(input_channels=input_size, output_channels=output_size)\n",
    "            random_input = torch.randn(4, input_size, 64, 64)\n",
    "\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = F.conv2d(\n",
    "                input=random_input,\n",
    "                weight=conv.weight,\n",
    "                groups=conv.groups,\n",
    "                stride=conv.stride,\n",
    "                dilation=conv.dilation,\n",
    "                bias=torch.zeros(output_size),\n",
    "                padding=0,\n",
    "            )\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FilterTest(unittest.TestCase):\n",
    "    \"\"\"A suite of tests that numerically checks the filtering operation\"\"\"\n",
    "\n",
    "    class Filter2D(nn.Module):\n",
    "        def __init__(self, channels: int, kernel: torch.Tensor):\n",
    "            super().__init__()\n",
    "            self.register_buffer('filter', kernel[None, None, :, :].repeat(channels, 1, 1, 1))\n",
    "\n",
    "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            b, c, h, w = x.shape\n",
    "            return F.conv2d(\n",
    "                x,\n",
    "                self.filter,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                groups=c,\n",
    "            )\n",
    "\n",
    "    def test_filter(self):\n",
    "        blur_sizes = list(range(1, 7))\n",
    "        for blur_size in blur_sizes:\n",
    "            # create a filter stub\n",
    "            blur_kernel = get_blur_kernel(blur_size)\n",
    "            conv = MyFilterStub(filter=blur_kernel, input_channels=128)\n",
    "            test_conv = self.Filter2D(128, blur_kernel)\n",
    "            random_input = torch.randn(4, 128, 64, 64)\n",
    "            output = conv.forward(random_input)\n",
    "            test_output = test_conv.forward(random_input)\n",
    "\n",
    "            self.assertTrue(torch.allclose(output, test_output, atol=ATOL))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92fb5087-bcaf-409e-8cc6-2b11f45ca06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "convTests = ConvTests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4495900-77d9-429a-a105-1c5ac4517b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "convTests.test_square_kernels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ba1558-9793-4618-8d59-0c07de49abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "convTests.test_horizontal_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02043cd9-0a19-4767-978a-97334a84e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "convTests.test_vertical_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7775cda-26eb-479a-a5da-45c7a98c9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "convTests.test_increasing_filter_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3022725-4080-47ca-8a51-3e167a4f73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "convTests.test_decreasing_filter_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0146cc88-8d20-4937-8230-50d7590a469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "convTests.test_same_number_of_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8822d51f-ec83-4c29-b135-7e23b9afb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "convTests.test_stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d22756a-4f96-41f3-ae54-aa2e0f8e2ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "False is not true",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mconvTests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_dilation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 177\u001b[0m, in \u001b[0;36mConvTests.test_dilation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m output \u001b[38;5;241m=\u001b[39m conv\u001b[38;5;241m.\u001b[39mforward(random_input)\n\u001b[0;32m    168\u001b[0m test_output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mrandom_input,\n\u001b[0;32m    170\u001b[0m     weight\u001b[38;5;241m=\u001b[39mconv\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    174\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    175\u001b[0m )\n\u001b[1;32m--> 177\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massertTrue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mATOL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py:727\u001b[0m, in \u001b[0;36mTestCase.assertTrue\u001b[1;34m(self, expr, msg)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m expr:\n\u001b[0;32m    726\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_formatMessage(msg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not true\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m safe_repr(expr))\n\u001b[1;32m--> 727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfailureException(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: False is not true"
     ]
    }
   ],
   "source": [
    "convTests.test_dilation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88f070c2-e9ed-4966-abc0-821b2804db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "convTests.test_biased_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27c82924-5a58-40b0-a69e-386c5c6b1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "convTests.test_zero_biased_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1ae795f-bf94-4a23-bbc5-fbfa4f0088db",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (32) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mconvTests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_grouping\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 186\u001b[0m, in \u001b[0;36mConvTests.test_grouping\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m conv \u001b[38;5;241m=\u001b[39m groups_size_stub_constructor(num_groups\u001b[38;5;241m=\u001b[39mgroup)\n\u001b[0;32m    184\u001b[0m random_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m--> 186\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m test_output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mrandom_input,\n\u001b[0;32m    189\u001b[0m     weight\u001b[38;5;241m=\u001b[39mconv\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    194\u001b[0m )\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massertTrue(torch\u001b[38;5;241m.\u001b[39mallclose(output, test_output, atol\u001b[38;5;241m=\u001b[39mATOL))\n",
      "File \u001b[1;32mD:\\Sc\\CNN_HW\\code\\conv.py:54\u001b[0m, in \u001b[0;36mMyConvStub.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m h_out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(output_height):\n\u001b[0;32m     53\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m w_out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(output_width):\n\u001b[1;32m---> 54\u001b[0m                 output[b, c_out, h_out, w_out] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mD:\\Sc\\CNN_HW\\code\\conv.py:70\u001b[0m, in \u001b[0;36mMyConvStub._conv_forward\u001b[1;34m(self, h_out, w_out, c_out, b, input_data)\u001b[0m\n\u001b[0;32m     67\u001b[0m field \u001b[38;5;241m=\u001b[39m input_data[b, :, h_start:h_end:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, w_start:w_end:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation]\n\u001b[0;32m     68\u001b[0m weight_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[c_out, :, :, :]\n\u001b[1;32m---> 70\u001b[0m field \u001b[38;5;241m=\u001b[39m \u001b[43mfield\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_channel\u001b[49m\n\u001b[0;32m     71\u001b[0m output \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (32) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "convTests.test_grouping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0377ca9b-073b-4a16-8466-9bd87db04c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterTest = FilterTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "442e33c2-1f6b-4a7f-ac73-cbc26eb35c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterTest.test_filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe26a8-8997-4d52-92eb-4fcb5ff4cac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
