{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66653,"databundleVersionId":7500999,"sourceType":"competition"},{"sourceId":8173230,"sourceType":"datasetVersion","datasetId":4837551}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":42.279973,"end_time":"2024-04-20T08:58:22.401618","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-20T08:57:40.121645","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"05848f34e126407ea8e741c2e28eeaac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ee24d5acd23485ea2c54e368cd95a1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3a60aeb39854f429b59e98e3f622257","IPY_MODEL_bd3d1371e29349b898d1de085a6fcb9b","IPY_MODEL_997957419c9e427493816003b8b4e859"],"layout":"IPY_MODEL_f22afcd86fc64cbb803e562d7c0f64e6"}},"4d7ee6efbee44415a2c0fb5fdefd58b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ed0c71529634d11b3a0a458f55ecc95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"997957419c9e427493816003b8b4e859":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef731c372d794e68bb770c34b6f66d83","placeholder":"​","style":"IPY_MODEL_6ed0c71529634d11b3a0a458f55ecc95","value":" 10/10 [00:00&lt;00:00, 11.06 examples/s]"}},"a13ec9d5b8f441d680229ad8d04853c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd3d1371e29349b898d1de085a6fcb9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05848f34e126407ea8e741c2e28eeaac","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7f0ecc3651046f6b0d5878ca30cc366","value":10}},"d7f0ecc3651046f6b0d5878ca30cc366":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3a60aeb39854f429b59e98e3f622257":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a13ec9d5b8f441d680229ad8d04853c2","placeholder":"​","style":"IPY_MODEL_4d7ee6efbee44415a2c0fb5fdefd58b6","value":"Map (num_proc=4): 100%"}},"ef731c372d794e68bb770c34b6f66d83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f22afcd86fc64cbb803e562d7c0f64e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport os\nimport re\nimport bisect\nfrom pathlib import Path\n\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer\nfrom spacy.lang.en import English\nfrom transformers.models.deberta_v2 import DebertaV2ForTokenClassification, DebertaV2TokenizerFast\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase\nfrom transformers.trainer import Trainer\nfrom transformers.training_args import TrainingArguments\nfrom transformers.data.data_collator import DataCollatorForTokenClassification\nfrom transformers import BertForTokenClassification\n\nINFERENCE_MAX_LENGTH = 512\nCONF_THRESH = 0.90\nURL_THRESH = 0.1\nAMP = True\nMODEL_PATH = '/kaggle/input/bert-base-ner-pii-training/output/fold_3/checkpoint-5000'\nDATA_DIR = '/kaggle/input/pii-detection-removal-from-educational-data/'\n\nnlp = English()\n\ndef find_span(target: list[str], document: list[str]) -> list[list[int]]:\n    idx = 0\n    spans = []\n    span = []\n\n    for i, token in enumerate(document):\n        if token != target[idx]:\n            idx = 0\n            span = []\n            continue\n        span.append(i)\n        idx += 1\n        if idx == len(target):\n            spans.append(span)\n            span = []\n            idx = 0\n            continue\n    \n    return spans\n\ndef spacy_to_hf(data: dict, idx: int) -> slice:\n    str_range = np.where(np.array(data[\"token_map\"]) == idx)[0]\n    start_idx = bisect.bisect_left([off[1] for off in data[\"offset_mapping\"]], str_range.min())\n    end_idx = start_idx\n    while end_idx < len(data[\"offset_mapping\"]):\n        if str_range.max() > data[\"offset_mapping\"][end_idx][1]:\n            end_idx += 1\n            continue\n        break\n    token_range = slice(start_idx, end_idx+1)\n    return token_range\n\nclass CustomTokenizer:\n    def __init__(self, tokenizer: PreTrainedTokenizerBase, max_length: int) -> None:\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __call__(self, example: dict) -> dict:\n        text = []\n        token_map = []\n\n        for idx, (t, ws) in enumerate(zip(example[\"tokens\"], example[\"trailing_whitespace\"])):\n            text.append(t)\n            token_map.extend([idx]*len(t))\n            if ws:\n                text.append(\" \")\n                token_map.append(-1)\n\n        tokenized = self.tokenizer(\n            \"\".join(text),\n            return_offsets_mapping=True,\n            truncation=True,\n            max_length=self.max_length,\n        )\n\n        return {**tokenized,\"token_map\": token_map,}\n\nwith open(str(Path(DATA_DIR).joinpath(\"test.json\")), \"r\") as f:\n    data = json.load(f)\n\nds = Dataset.from_dict({\n    \"full_text\": [x[\"full_text\"] for x in data],\n    \"document\": [x[\"document\"] for x in data],\n    \"tokens\": [x[\"tokens\"] for x in data],\n    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n})\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\nds = ds.map(CustomTokenizer(tokenizer=tokenizer, max_length=INFERENCE_MAX_LENGTH), num_proc=os.cpu_count())\n\nfrom transformers import AutoModelForTokenClassification\n\nmodel = AutoModelForTokenClassification.from_pretrained(MODEL_PATH)\ncollator = DataCollatorForTokenClassification(tokenizer)\nargs = TrainingArguments(\".\", per_device_eval_batch_size=1, report_to=\"none\", fp16=AMP)\ntrainer = Trainer(\n    model=model, args=args, data_collator=collator, tokenizer=tokenizer,\n)\n\npredictions = trainer.predict(ds).predictions  # (n_sample, len, n_labels)\npred_softmax = torch.softmax(torch.from_numpy(predictions), dim=2).numpy()\nid2label = model.config.id2label\no_index = model.config.label2id[\"O\"]\npreds = predictions.argmax(-1)\npreds_without_o = pred_softmax.copy()\npreds_without_o[:,:,o_index] = 0\npreds_without_o = preds_without_o.argmax(-1)\no_preds = pred_softmax[:,:,o_index]\npreds_final = np.where(o_preds < CONF_THRESH, preds_without_o , preds)\n\nprocessed =[]\npairs = set()\n\nfor p, token_map, offsets, tokens, doc in zip(\n    preds_final, ds[\"token_map\"], ds[\"offset_mapping\"], ds[\"tokens\"], ds[\"document\"]\n):\n    for token_pred, (start_idx, end_idx) in zip(p, offsets):\n        label_pred = id2label[token_pred]\n\n        if start_idx + end_idx == 0:\n            continue\n\n        if token_map[start_idx] == -1:\n            start_idx += 1\n\n        while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n            start_idx += 1\n\n        if start_idx >= len(token_map): \n            break\n\n        token_id = token_map[start_idx]\n        pair = (doc, token_id)\n\n        if label_pred in (\"O\", \"B-EMAIL\", \"B-URL_PERSONAL\", \"B-PHONE_NUM\", \"I-PHONE_NUM\") or token_id == -1:\n            continue        \n\n        if pair in pairs:\n            continue\n            \n        processed.append(\n            {\"document\": doc, \"token\": token_id, \"label\": label_pred, \"token_str\": tokens[token_id]}\n        )\n        pairs.add(pair)\n\nurl_whitelist = [\n    \"wikipedia.org\",\n    \"coursera.org\",\n    \"google.com\",\n    \".gov\",\n]\nurl_whitelist_regex = re.compile(\"|\".join(url_whitelist))\n\nfor row_idx, _data in enumerate(ds):\n    for token_idx, token in enumerate(_data[\"tokens\"]):\n        if not nlp.tokenizer.url_match(token):\n            continue\n        print(f\"Found URL: {token}\")\n        if url_whitelist_regex.search(token) is not None:\n            print(\"The above is in the whitelist\")\n            continue\n        input_idxs = spacy_to_hf(_data, token_idx)\n        probs = pred_softmax[row_idx, input_idxs, model.config.label2id[\"B-URL_PERSONAL\"]]\n        if probs.mean() > URL_THRESH:\n            print(\"The above is PII\")\n            processed.append(\n                {\n                    \"document\": _data[\"document\"], \n                    \"token\": token_idx, \n                    \"label\": \"B-URL_PERSONAL\", \n                    \"token_str\": token\n                }\n            )\n            pairs.add((_data[\"document\"], token_idx))\n        else:\n            print(\"The above is not PII\")\n\nemail_regex = re.compile(r'[\\w.+-]+@[\\w-]+\\.[\\w.-]+')\nphone_num_regex = re.compile(r\"(\\(\\d{3}\\)\\d{3}\\-\\d{4}\\w*|\\d{3}\\.\\d{3}\\.\\d{4})\\s\")\nemails = []\nphone_nums = []\n\nfor _data in ds:\n    for token_idx, token in enumerate(_data[\"tokens\"]):\n        if re.fullmatch(email_regex, token) is not None:\n            emails.append(\n                {\"document\": _data[\"document\"], \"token\": token_idx, \"label\": \"B-EMAIL\", \"token_str\": token}\n            )\n    matches = phone_num_regex.findall(_data[\"full_text\"])\n    if not matches:\n        continue\n    for match in matches:\n        target = [t.text for t in nlp.tokenizer(match)]\n        matched_spans = find_span(target, _data[\"tokens\"])\n    for matched_span in matched_spans:\n        for intermediate, token_idx in enumerate(matched_span):\n            prefix = \"I\" if intermediate else \"B\"\n            phone_nums.append(\n                {\"document\": _data[\"document\"], \"token\": token_idx, \"label\": f\"{prefix}-PHONE_NUM\", \"token_str\": _data[\"tokens\"][token_idx]}\n            )\n\ndf = pd.DataFrame(processed + emails + phone_nums)\ndf[\"row_id\"] = list(range(len(df)))\ndf.head(100)\n\ndf[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)","metadata":{"_uuid":"e5d093df-20c4-4e8f-be46-ecd48e2165bc","_cell_guid":"d3eb76ba-19c1-4eaf-a321-0673902afe95","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}