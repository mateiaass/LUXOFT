{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EpaF-9x5-t_"
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install rowordnet\n",
    "!pip install phunspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_12MmtN8_N4v"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import rowordnet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import phunspell\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "# 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\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v--JtrbxANfb"
   },
   "outputs": [],
   "source": [
    "wn = rowordnet.RoWordNet()\n",
    "pspell = phunspell.Phunspell('ro_RO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KMgCyhE55L5"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mateiaassAI/MarcellP\", streaming = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "IEZBuJ6OXrgT"
   },
   "outputs": [],
   "source": [
    "dictio_words = {1: {0: 0.0, 1: 0.5, 2: 1.01},\n",
    "          3: {1: 0.0, 2: 0.5, 3: 1.01},\n",
    "          6: {2: 0.0, 3: 0.3, 4: 0.75, 5: 1.01},\n",
    "          9: {3: 0.0, 4: 0.15, 5: 0.4, 6: 0.7, 7: 1.01},\n",
    "          16: {3: 0.0, 4: 0.1, 5: 0.4, 6: 0.7, 7: 0.85, 8: 1.01},\n",
    "          20: {4: 0.0, 5: 0.1, 6: 0.4, 7: 0.7, 8: 0.85, 9: 1.01},\n",
    "          30: {5: 0.0, 6: 0.1, 7: 0.4, 8: 0.7, 9: 0.85, 10: 1.01},\n",
    "          100000000: None}\n",
    "\n",
    "def number_of_words_changed(sentence_length):\n",
    "  prob = random.randint(1, 100) / 100\n",
    "  keys = list(dictio_words.keys())\n",
    "  little_dict = {}\n",
    "  for i in range(len(dictio_words) - 1):\n",
    "      if sentence_length >= keys[i] and sentence_length < keys[i+1]:\n",
    "          little_dict = dictio_words[keys[i]]\n",
    "          values = list(little_dict.values())\n",
    "          for j in range(len(values) - 1):\n",
    "              if prob >= values[j] and prob < values[j+1]:\n",
    "                  return list(little_dict.keys())[list(little_dict.values()).index(values[j])]\n",
    "\n",
    "dictio_spell = {1: {0: 0.0, 1: 1.01},\n",
    "          3: {1: 0.0, 2: 1.01},\n",
    "          5: {1: 0.0, 2: 0.8, 3: 1.01},\n",
    "          10: {1: 0.0, 2: 0.75, 3: 0.9, 4: 1.01},\n",
    "          100000000: None}\n",
    "\n",
    "def number_of_misspellings(word_length):\n",
    "\n",
    "\n",
    "  prob = random.randint(1, 100) / 100\n",
    "\n",
    "  keys = list(dictio_spell.keys())\n",
    "  little_dict = {}\n",
    "  for i in range(len(dictio_spell) - 1):\n",
    "      if word_length >= keys[i] and word_length < keys[i+1]:\n",
    "          little_dict = dictio_spell[keys[i]]\n",
    "          values = list(little_dict.values())\n",
    "          for j in range(len(values) - 1):\n",
    "              if prob >= values[j] and prob < values[j+1]:\n",
    "                  return list(little_dict.keys())[list(little_dict.values()).index(values[j])]\n",
    "\n",
    "mispell_replacement_candidates = {\n",
    "    'a': ['ea', 'ă', 'â', 'au', 'q', 'w', 's', 'z'],\n",
    "    'ă': ['e', 'â', 'a', 'p', 'î', 'ț', 'ș'],\n",
    "    'â': ['î', 'ă', 'a', 'ț'],\n",
    "    'b': ['v', 'd', 'p', 'v', 'g', 'h', 'n'],\n",
    "    'c': ['k', 'g', 'x', 'd', 'f', 'v'],\n",
    "    'd': ['b', 'p', 'e', 'r', 's', 'f', 'x', 'c'],\n",
    "    'e': ['ie', 'i', 'ă', 'ea', 'esc', 'w', 's', 'd', 'r'],\n",
    "    'f': ['r', 'g', 'd', 'c', 'v'],\n",
    "    'g': ['c', 't', 'h', 'f', 'v', 'b'],\n",
    "    'h': ['y', 'g', 'j', 'b', 'n'],\n",
    "    'i': ['ii', 'iii', 'e', 'î', 'y', 'ie', 'l', 'u', 'o', 'j', 'k'],\n",
    "    'î': ['â', 'i', 'ă', 'ț'],\n",
    "    'j': ['ș', 'u', 'h', 'k', 'n', 'm'],\n",
    "    'k': ['c', 'i', 'j', 'l', 'm'],\n",
    "    'l': ['n', 'i', 'o', 'p', 'k'],\n",
    "    'm': ['n', 'j', 'k'],\n",
    "    'n': ['m', 'l', 'j', 'h', 'b'],\n",
    "    'o': ['u', 'or', 'i', 'k', 'l', 'p'],\n",
    "    'p': ['q', 'b', 'd', 'o', 'l'],\n",
    "    'q': ['c', 'p', 'w', 'a'],\n",
    "    'r': ['e', 'd', 't', 'f'],\n",
    "    's': ['ș', 'z', 'w', 'a', 'd', 's', 'z'],\n",
    "    'ș': ['j', 's', 'ă', 'ț', 'p', 'l'],\n",
    "    't': ['ț', 'r', 'f', 'g', 'y'],\n",
    "    'ț': ['t', 'ă', 'â', 'ș', 'î'],\n",
    "    'u': ['v', 'o', 'y', 'h', 'j', 'i'],\n",
    "    'v': ['w', 'u', 'b', 'vr', 'c', 'f', 'g'],\n",
    "    'w': ['v', 'q', 'e', 'a', 's'],\n",
    "    'x': ['cs', 'gz', 'cș', 's', 'd', 'z', 'c'],\n",
    "    'y': ['i', 't', 'u', 'g', 'h'],\n",
    "    'z': ['s', 'a', 'x'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "cTfV5ukCbpFx"
   },
   "outputs": [],
   "source": [
    "punctuation_dict = {\n",
    "    ' ': {' ': 0.00, ',': 0.95, '-----': 1.01},\n",
    "    ',': {' ': 0.00, ',': 0.41, '.': 0.85, '-----': 1.01},\n",
    "    ';': {' ': 0.00, ',': 0.80, ';': 0.89, '-----': 1.01},\n",
    "    ':': {' ': 0.00, ',': 0.86, ':': 0.91, '-----': 1.01},\n",
    "    '-': {' ': 0.00, '-': 0.80, '-----': 1.01},\n",
    "    '.': {' ': 0.00, ';': 0.16, '.': 0.26, '...': 0.95, '-----': 1.01},\n",
    "    '?': {' ': 0.00, '.': 0.80, '?': 0.84, '!': 0.96, '-----': 1.01},\n",
    "    '!': {' ': 0.00, '.': 0.80, '?': 0.90, '!': 0.97, '-----': 1.01},\n",
    "    '...': {' ': 0.00, '...': 0.80, '-----': 1.01}\n",
    "  }\n",
    "\n",
    "def punctuation_substitution(letter):\n",
    "  prob = random.randint(1, 100) / 100\n",
    "  keys = list(punctuation_dict.keys())\n",
    "  little_dict = punctuation_dict[letter]\n",
    "  values = list(little_dict.values())\n",
    "  for i in range(len(values) - 1):\n",
    "    if prob >= values[i] and prob < values[i+1]:\n",
    "      return list(little_dict.keys())[list(little_dict.values()).index(values[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "nY0_ga4pbg9U"
   },
   "outputs": [],
   "source": [
    "def copy_word(sentence, word, isSpace = True):\n",
    "  if isSpace:\n",
    "    sentence = sentence + \" \" + word\n",
    "  else:\n",
    "    sentence = sentence + word\n",
    "  return sentence\n",
    "\n",
    "def concatenate(sentence, word1, word2, isSpace = True):\n",
    "  if isSpace:\n",
    "    sentence = sentence + \" \" + word1 + word2\n",
    "  else:\n",
    "    sentence = sentence + word1 + word2\n",
    "  return sentence\n",
    "\n",
    "def transpose(sentence, word1, word2, isSpace = True):\n",
    "  if isSpace:\n",
    "    sentence = sentence + \" \" + word2 + \" \" + word1\n",
    "  else:\n",
    "    sentence = sentence + word2 + \" \" + word1\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "pboKH9FYyXSO"
   },
   "outputs": [],
   "source": [
    "def copy_letter(word, letter):\n",
    "  return word + letter\n",
    "\n",
    "def transpose_letters(word, letter1, letter2):\n",
    "  return word + letter2 + letter1\n",
    "\n",
    "def replace_letter(word, letter):\n",
    "  return word + letter\n",
    "\n",
    "def insert_letter(word, letter, new_letter):\n",
    "  return word + letter + new_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "APZfrT8BvA2o"
   },
   "outputs": [],
   "source": [
    "alphabet = \"аăâbcdefghiîjklmnopqrsștțuvwxyz\"\n",
    "alphabet2 = \"аăâbcdefghiîjklmnopqrsștțuvwxyz-\"\n",
    "\n",
    "def misspell(word):\n",
    "  number_of_changed_letters = number_of_misspellings(len(word))\n",
    "  letters_to_be_changed = np.random.choice(np.arange(0, len(word)), size=number_of_changed_letters, replace=False).tolist()\n",
    "  wrong_word = \"\"\n",
    "  skip_flag = False\n",
    "  for i in range(len(word)):\n",
    "    if skip_flag == True:\n",
    "      skip_flag = False\n",
    "      continue\n",
    "    letter = word[i]\n",
    "\n",
    "    # Letter not to be changed\n",
    "    if i not in letters_to_be_changed:\n",
    "      wrong_word = copy_letter(wrong_word, letter)\n",
    "      continue\n",
    "\n",
    "    # Type of misspelling - Distribution of Probability\n",
    "    letter_error_action = random.randint(1, 100) / 100\n",
    "\n",
    "    # DELETION\n",
    "    if letter_error_action <= 0.25:\n",
    "      continue\n",
    "\n",
    "    # INSERTION\n",
    "    if letter_error_action > 0.25 and letter_error_action <= 0.40:\n",
    "      alphabet_letter = alphabet2[random.randint(0, len(alphabet2) - 1)]\n",
    "      wrong_word = insert_letter(wrong_word, letter, alphabet_letter)\n",
    "      continue\n",
    "\n",
    "    # TRANSPOSITION\n",
    "    if letter_error_action > 0.40 and letter_error_action <= 0.65 and i < len(word) - 1:\n",
    "      next_letter = word[i + 1]\n",
    "      wrong_word = transpose_letters(wrong_word, letter, next_letter)\n",
    "      skip_flag = True\n",
    "      continue\n",
    "\n",
    "    # REPLACEMENT\n",
    "    if letter_error_action > 0.65:\n",
    "      if letter.lower() not in alphabet:\n",
    "        alphabet_letter = letter\n",
    "      else:\n",
    "        if letter_error_action <= 0.68 and i == 0:\n",
    "          alphabet_letter = letter.lower() if letter.islower() else letter.upper()\n",
    "\n",
    "        if letter_error_action <= 0.7 and i == len(word) - 1 and letter.lower() in ['a', 'i', 'l']:\n",
    "          continue\n",
    "\n",
    "        if letter_error_action > 0.90:\n",
    "          alphabet_letter = alphabet[random.randint(0, len(alphabet) - 1)]\n",
    "        else:\n",
    "            alphabet_letter = random.choice(mispell_replacement_candidates[letter.lower()])\n",
    "\n",
    "      wrong_word = replace_letter(wrong_word, alphabet_letter)\n",
    "      continue\n",
    "\n",
    "    # DEFAULT\n",
    "    wrong_word = copy_letter(wrong_word, letter)\n",
    "\n",
    "  return wrong_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "PcO7ZeN3xlWW"
   },
   "outputs": [],
   "source": [
    "def morphologic_dex(word):\n",
    "  if len(word) <= 3:\n",
    "    return word\n",
    "\n",
    "  url = f'https://dexonline.ro/definitie/{word}/paradigma'\n",
    "  response = requests.get(url)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    para_lexemes = soup.find_all('div', class_='paraLexeme')\n",
    "\n",
    "    for para_lexeme in para_lexemes:\n",
    "      lexeme_name = para_lexeme.find('span', class_='lexemeName').text\n",
    "      if lexeme_name == word:\n",
    "        table = para_lexeme.find('table', class_='lexeme')\n",
    "\n",
    "        if table:\n",
    "          unique_cells = set()\n",
    "          form_cells = table.find_all('td', class_='form')\n",
    "\n",
    "          for cell in form_cells:\n",
    "            if not cell.find(class_='elisionHidden') and not cell.find(class_='notRecommendedHidden'):\n",
    "              text = cell.get_text(strip=True)\n",
    "              if '—' not in text:\n",
    "                text = text.replace(')', ' ').replace('(', '')\n",
    "                unique_cells.add(text)\n",
    "\n",
    "          if unique_cells:\n",
    "            random_word = random.choice(list(unique_cells))\n",
    "            return random_word\n",
    "  return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "c9GUbngn7ttP"
   },
   "outputs": [],
   "source": [
    "lista_conjunctii = ['și', 'dar', 'iar', 'că', 'să', 'ci', 'fie', 'sau', 'ori', 'ci și', 'ca să', 'încât să', 'nici', 'însă', 'ba', 'deci', 'așadar', 'totuși', 'însăși', 'chiar', 'tot', 'încă', 'atât', 'pe când', 'în timp ce',\n",
    "                    'cu toate că', 'întrucât', 'precum', 'totodată', 'care', 'pe care']\n",
    "\n",
    "lista_prepozitii = ['la', 'în', 'către', 'contrar', 'fără', 'după', 'cu', 'lângă', 'asupra', 'de', 'de la', 'despre', 'dimprejurul', 'din', 'dinaintea', 'înspre', 'între', 'înăuntrul', 'împotriva', 'împrejurul', 'înaintea',\n",
    "                    'înapoia', 'întru', 'dedesubtul', 'datorită', 'printre', 'prin', 'primprejur', 'peste', 'pentru', 'pe', 'până', 'via', 'spre', 'sub', 'din cauza', 'din pricina', 'în vederea', 'cu excepția', 'cu tot cu', 'a']\n",
    "\n",
    "lista_articole_posesive = ['a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor', 'a', 'ai', 'ale', 'al', 'alor']\n",
    "lista_articole_demonstrative = ['cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor', 'cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor', 'cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor', 'cel', 'cea', 'cei', 'cele', 'celui', 'celei', 'celor']\n",
    "lista_articole_nehotarate = ['un', 'o', 'niste', 'unor', 'unui', 'unei', 'un', 'o', 'niste', 'unor', 'unui', 'unei', 'un', 'o', 'niste', 'unor', 'unui', 'unei','un', 'o', 'niste', 'unor', 'unui', 'unei']\n",
    "\n",
    "def substitute(word_metadata):\n",
    "  action = random.randint(1, 100) / 100\n",
    "\n",
    "  if len(word_metadata['FORM']) > 8 and action > 0.6:\n",
    "    action = 0.5\n",
    "\n",
    "  # RoWORDNET\n",
    "  if action <= 0.2:\n",
    "    word = word_metadata['LEMMA'].lower()\n",
    "    syn_list = []\n",
    "    synset_ids = wn.synsets(literal=word)\n",
    "    for s in synset_ids:\n",
    "      if word in wn.synset(s).literals:\n",
    "        for literal in wn.synset(s).literals:\n",
    "          if literal != word and literal not in syn_list:\n",
    "            syn_list.append(literal)\n",
    "    if len(syn_list) > 0:\n",
    "      return random.choice(syn_list)\n",
    "    else:\n",
    "      return word_metadata['FORM']\n",
    "\n",
    "  # DEXONLINE\n",
    "  elif action > 0.2 and action <= 0.6:\n",
    "\n",
    "    if word_metadata['UPOS'] == 'CONJ' and action <= 0.3:\n",
    "      return random.choice(lista_conjunctii)\n",
    "\n",
    "    if word_metadata['UPOS'] == 'ADP' and action <= 0.3:\n",
    "      return random.choice(lista_prepozitii)\n",
    "\n",
    "    if word_metadata['UPOS'] == 'DET' and word_metadata['FORM'] in lista_articole_posesive and action <= 0.3:\n",
    "      return random.choice(lista_articole_posesive)\n",
    "    if word_metadata['UPOS'] == 'DET' and word_metadata['FORM'] in lista_articole_demonstrative and action <= 0.3:\n",
    "      return random.choice(lista_articole_demonstrative)\n",
    "\n",
    "    if word_metadata['UPOS'] == 'DET' and word_metadata['FORM'] in lista_articole_nehotarate and action <= 0.3:\n",
    "      return random.choice(lista_articole_nehotarate)\n",
    "    return morphologic_dex(word_metadata['LEMMA'])\n",
    "\n",
    "  # SPELLCHECKER\n",
    "  elif action > 0.6:\n",
    "    sugestions = list(pspell.suggest(word_metadata['FORM']))\n",
    "    if len(sugestions) == 0:\n",
    "      return morphologic_dex(word_metadata['LEMMA'])\n",
    "    return random.choice(sugestions)\n",
    "\n",
    "  return word_metadata['FORM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "4YRo4YmSGLOy"
   },
   "outputs": [],
   "source": [
    "def save_data(data, counter):\n",
    "  output_file = f'MEID/{counter}.jsonl'\n",
    "  with open(output_file, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    for example_parsed in data:\n",
    "      json.dump(example_parsed, json_file, ensure_ascii=False)#, indent=4)\n",
    "      json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqr52hP3TGBU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "161000 2024-05-03 08:33:03.519699\n",
      "162000 2024-05-03 08:37:36.079144\n",
      "163000 2024-05-03 08:42:05.886978\n",
      "164000 2024-05-03 08:47:51.318783\n",
      "165000 2024-05-03 08:53:09.352855\n",
      "166000 2024-05-03 08:58:04.620134\n",
      "167000 2024-05-03 09:03:06.611880\n",
      "168000 2024-05-03 09:08:12.291771\n",
      "169000 2024-05-03 09:13:11.445643\n",
      "170000 2024-05-03 09:18:51.791437\n",
      "171000 2024-05-03 09:23:58.825889\n",
      "172000 2024-05-03 09:27:21.451503\n",
      "173000 2024-05-03 09:30:39.060903\n",
      "174000 2024-05-03 09:33:53.884191\n",
      "175000 2024-05-03 09:37:36.474336\n",
      "176000 2024-05-03 09:41:13.181639\n",
      "177000 2024-05-03 09:46:30.147453\n",
      "178000 2024-05-03 09:51:29.583598\n",
      "179000 2024-05-03 09:57:04.744611\n",
      "180000 2024-05-03 10:01:49.842835\n",
      "180000 2024-05-03 10:01:50.326091\n",
      "181000 2024-05-03 10:07:03.418940\n",
      "182000 2024-05-03 10:12:41.226034\n",
      "183000 2024-05-03 10:17:12.667054\n",
      "184000 2024-05-03 10:22:10.523038\n",
      "185000 2024-05-03 10:25:54.870267\n",
      "186000 2024-05-03 10:29:22.872849\n",
      "187000 2024-05-03 10:34:15.730923\n",
      "188000 2024-05-03 10:38:52.461807\n",
      "189000 2024-05-03 10:42:42.829175\n",
      "190000 2024-05-03 10:46:40.768849\n",
      "191000 2024-05-03 10:51:41.671986\n",
      "192000 2024-05-03 10:56:36.394809\n",
      "193000 2024-05-03 11:01:02.875041\n",
      "194000 2024-05-03 11:05:44.346885\n",
      "195000 2024-05-03 11:10:34.602743\n",
      "196000 2024-05-03 11:16:12.294702\n",
      "197000 2024-05-03 11:20:56.998138\n",
      "198000 2024-05-03 11:26:39.201038\n",
      "199000 2024-05-03 11:32:26.613389\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset[\"train\"])\n",
    "count = 0\n",
    "data = []\n",
    "\n",
    "punctuation_list = [' ', ',', ';', ':', '-', '.', '?', '!', '...']\n",
    "\n",
    "contor_file = 9\n",
    "breakline = 20000\n",
    "deadline = 200000\n",
    "after_limit = 160000\n",
    "\n",
    "for example in iterator:\n",
    "    count += 1\n",
    "    if count <= after_limit:\n",
    "        if count % breakline == 0:\n",
    "            print(count)\n",
    "        continue\n",
    "\n",
    "    if count % 1000 == 0:\n",
    "        print(count, datetime.datetime.now())\n",
    "\n",
    "    correct_sentence = example['text']\n",
    "    metadata = example['metadata_text']\n",
    "\n",
    "    list_of_words = [word['FORM'] for word in metadata if word['FEATS'] != '_']\n",
    "\n",
    "    word_count = len(list_of_words)\n",
    "    if word_count <= 3:\n",
    "        continue\n",
    "    \n",
    "    nr_errs = number_of_words_changed(word_count)\n",
    "    numbers_to_be_changed = np.random.choice(np.arange(0, word_count), size=nr_errs, replace=False).tolist()\n",
    "\n",
    "    skip_flag = False\n",
    "    wrong_sentence = \"\"\n",
    "    nr_word = -1\n",
    "    for i in range(len(metadata)):\n",
    "      if skip_flag == True:\n",
    "        skip_flag = False\n",
    "        nr_word += 1\n",
    "        continue\n",
    "\n",
    "      word = metadata[i]\n",
    "      if word['FEATS'] == '_':\n",
    "        if word['FORM'] in punctuation_list:\n",
    "          new_punctuation = punctuation_substitution(word['FORM'])\n",
    "          if new_punctuation in ['-', ' ']:\n",
    "            wrong_sentence = copy_word(wrong_sentence, new_punctuation, False)\n",
    "        else:\n",
    "          wrong_sentence = copy_word(wrong_sentence, word['FORM'])\n",
    "\n",
    "        continue\n",
    "\n",
    "      nr_word += 1\n",
    "\n",
    "      # Token not to be changed\n",
    "      if nr_word not in numbers_to_be_changed:\n",
    "        wrong_sentence = copy_word(wrong_sentence, word['FORM'])\n",
    "        continue\n",
    "\n",
    "      # Type of error - Distribution of Probability\n",
    "      token_error_action = random.randint(1, 100) / 100\n",
    "\n",
    "      # CONCATENATION\n",
    "      if token_error_action <= 0.12 and i < len(metadata) - 1:\n",
    "        next_word = metadata[i + 1]\n",
    "        if next_word['FEATS'] != '_':\n",
    "          wrong_sentence = concatenate(wrong_sentence, word['FORM'], next_word['FORM'])\n",
    "          skip_flag = True\n",
    "          continue\n",
    "\n",
    "      # TRANSPOSITION\n",
    "      if token_error_action > 0.12 and token_error_action <= 0.2 and i < len(metadata) - 1:\n",
    "        next_word = metadata[i + 1]\n",
    "        if next_word['FEATS'] != '_':\n",
    "          wrong_sentence = transpose(wrong_sentence, word['FORM'], next_word['FORM'])\n",
    "          skip_flag = True\n",
    "          continue\n",
    "\n",
    "      # DELETION\n",
    "      if token_error_action > 0.2 and token_error_action <= 0.25:\n",
    "        continue\n",
    "\n",
    "      # MISSPELLING\n",
    "      if token_error_action > 0.25 and token_error_action <= 0.7:\n",
    "        wrong_sentence = copy_word(wrong_sentence, misspell(word['FORM']))\n",
    "        continue\n",
    "\n",
    "      # SUBSTITUTION\n",
    "      if token_error_action > 0.7:\n",
    "        if word['UPOS'] in ['PROPN', 'NUM', 'SYM']:\n",
    "          wrong_sentence = copy_word(wrong_sentence, word['FORM'])\n",
    "        else:\n",
    "          wrong_sentence = copy_word(wrong_sentence, substitute(word))\n",
    "        continue\n",
    "\n",
    "      # DEFAULT\n",
    "      wrong_sentence = copy_word(wrong_sentence, word['FORM'])\n",
    "\n",
    "    data.append({\"wrong\": wrong_sentence[1:], \"right\": correct_sentence})\n",
    "\n",
    "    if count % breakline == 0:\n",
    "      contor_file += 1\n",
    "      print(count, datetime.datetime.now())\n",
    "      save_data(data, contor_file)\n",
    "      data = []\n",
    "\n",
    "    if count == deadline:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
