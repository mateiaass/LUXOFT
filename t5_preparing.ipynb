{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6bef00d9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:11:18.608155Z",
          "iopub.status.busy": "2024-05-12T15:11:18.607747Z",
          "iopub.status.idle": "2024-05-12T15:11:48.231751Z",
          "shell.execute_reply": "2024-05-12T15:11:48.230766Z"
        },
        "papermill": {
          "duration": 29.633484,
          "end_time": "2024-05-12T15:11:48.234289",
          "exception": false,
          "start_time": "2024-05-12T15:11:18.600805",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6bef00d9",
        "outputId": "7dc162ae-076b-4fab-d291-82220d1b77df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d18ab5fe",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:11:48.251451Z",
          "iopub.status.busy": "2024-05-12T15:11:48.250641Z",
          "iopub.status.idle": "2024-05-12T15:12:07.059728Z",
          "shell.execute_reply": "2024-05-12T15:12:07.058765Z"
        },
        "papermill": {
          "duration": 18.820589,
          "end_time": "2024-05-12T15:12:07.062198",
          "exception": false,
          "start_time": "2024-05-12T15:11:48.241609",
          "status": "completed"
        },
        "tags": [],
        "id": "d18ab5fe"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
        "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import nltk\n",
        "import evaluate\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7d3abf78",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:12:07.077582Z",
          "iopub.status.busy": "2024-05-12T15:12:07.076963Z",
          "iopub.status.idle": "2024-05-12T15:12:14.844307Z",
          "shell.execute_reply": "2024-05-12T15:12:14.843282Z"
        },
        "papermill": {
          "duration": 7.77743,
          "end_time": "2024-05-12T15:12:14.846627",
          "exception": false,
          "start_time": "2024-05-12T15:12:07.069197",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d3abf78",
        "outputId": "cb9f3c63-862b-4cb1-f7c2-76213386fd12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = \"dumitrescustefan/t5-v1_1-base-romanian\"\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
        "# model.generation_config.min_new_tokens = 0\n",
        "# model.generation_config.max_new_tokens = 256\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e6351c6b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:12:14.946562Z",
          "iopub.status.busy": "2024-05-12T15:12:14.946137Z",
          "iopub.status.idle": "2024-05-12T15:12:16.351636Z",
          "shell.execute_reply": "2024-05-12T15:12:16.350485Z"
        },
        "papermill": {
          "duration": 1.417894,
          "end_time": "2024-05-12T15:12:16.354177",
          "exception": false,
          "start_time": "2024-05-12T15:12:14.936283",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6351c6b",
        "outputId": "6ad55ba6-ebbe-4821-e50b-28076a59e82e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(64101, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "95a89c32",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:12:16.376611Z",
          "iopub.status.busy": "2024-05-12T15:12:16.375934Z",
          "iopub.status.idle": "2024-05-12T15:12:17.884512Z",
          "shell.execute_reply": "2024-05-12T15:12:17.883240Z"
        },
        "papermill": {
          "duration": 1.522933,
          "end_time": "2024-05-12T15:12:17.887075",
          "exception": false,
          "start_time": "2024-05-12T15:12:16.364142",
          "status": "completed"
        },
        "tags": [],
        "id": "95a89c32"
      },
      "outputs": [],
      "source": [
        "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f0fe512a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:12:17.905870Z",
          "iopub.status.busy": "2024-05-12T15:12:17.904937Z",
          "iopub.status.idle": "2024-05-12T15:12:28.405605Z",
          "shell.execute_reply": "2024-05-12T15:12:28.404629Z"
        },
        "papermill": {
          "duration": 10.512319,
          "end_time": "2024-05-12T15:12:28.407799",
          "exception": false,
          "start_time": "2024-05-12T15:12:17.895480",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0fe512a",
        "outputId": "f535d31f-ef63-4154-f310-667f5b6a6e1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Dataset({\n",
              "     features: ['wrong', 'right'],\n",
              "     num_rows: 1967695\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['wrong', 'right'],\n",
              "     num_rows: 60857\n",
              " })]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"mateiaassAI/MEID_v2\", split=['train[:97%]', 'train[97%:100%]'])\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = dataset[0]\n",
        "ds_test = dataset[1]\n",
        "ds_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX5UGl1Y_ObP",
        "outputId": "381330eb-7e67-42ae-d259-a011d75d1725"
      },
      "id": "LX5UGl1Y_ObP",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['wrong', 'right'],\n",
              "    num_rows: 60857\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation_marks = ['.', '?', '!', ';', '...']\n",
        "\n",
        "def filter_sentences(sentences):\n",
        "    text = sentences['right']\n",
        "    if any(text.endswith(punc) for punc in punctuation_marks):\n",
        "      words = text.split()\n",
        "      if len(words) >= 10:\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "SAFP_tE5AWtx"
      },
      "id": "SAFP_tE5AWtx",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fds_train = ds_train.filter(filter_sentences, batched=False)\n",
        "ds_test = ds_test.take(50000)\n",
        "# fds_test = ds_test.filter(filter_sentences, batched=False)"
      ],
      "metadata": {
        "id": "zHKnMZIO_149"
      },
      "id": "zHKnMZIO_149",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(fds_train))\n",
        "print(len(ds_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P_SMQYOCPA8",
        "outputId": "75bfb7cb-fd42-40c4-c23e-e4000423f970"
      },
      "id": "_P_SMQYOCPA8",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1007018\n",
            "50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1a57c307",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:12:28.434883Z",
          "iopub.status.busy": "2024-05-12T15:12:28.434297Z",
          "iopub.status.idle": "2024-05-12T15:12:28.440277Z",
          "shell.execute_reply": "2024-05-12T15:12:28.439407Z"
        },
        "papermill": {
          "duration": 0.021295,
          "end_time": "2024-05-12T15:12:28.442335",
          "exception": false,
          "start_time": "2024-05-12T15:12:28.421040",
          "status": "completed"
        },
        "tags": [],
        "id": "1a57c307"
      },
      "outputs": [],
      "source": [
        "prefix = \"\"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"wrong\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=256, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(text_target=examples[\"right\"],\n",
        "                          max_length=256,\n",
        "                          truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "44c38b44",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:12:28.468576Z",
          "iopub.status.busy": "2024-05-12T15:12:28.468005Z",
          "iopub.status.idle": "2024-05-12T15:15:10.302527Z",
          "shell.execute_reply": "2024-05-12T15:15:10.301530Z"
        },
        "papermill": {
          "duration": 161.849954,
          "end_time": "2024-05-12T15:15:10.304447",
          "exception": false,
          "start_time": "2024-05-12T15:12:28.454493",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44c38b44",
        "outputId": "fab72f42-7f25-4952-97af-b91d7ed517fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n"
          ]
        }
      ],
      "source": [
        "# tokenized_dataset = fds_train.take(1000000).map(preprocess_function, batched=True)\n",
        "tokenized_dataset = fds_train.take(100).map(preprocess_function, batched=True)\n",
        "tokenized_dataset_test = ds_test.map(preprocess_function, batched=True)\n",
        "print(len(tokenized_dataset_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b74c6863",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:15:10.331360Z",
          "iopub.status.busy": "2024-05-12T15:15:10.330727Z",
          "iopub.status.idle": "2024-05-12T15:15:10.338146Z",
          "shell.execute_reply": "2024-05-12T15:15:10.337352Z"
        },
        "papermill": {
          "duration": 0.023315,
          "end_time": "2024-05-12T15:15:10.340503",
          "exception": false,
          "start_time": "2024-05-12T15:15:10.317188",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b74c6863",
        "outputId": "e7e5109c-9b93-4786-8cfe-e65ff66231d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102\n",
            "107\n",
            "[183, 988, 24, 485, 7568, 8241, 6, 3, 3848, 763, 3, 5, 2048, 306, 7, 2069, 19, 784, 245, 7, 3255, 3, 191, 15328, 234, 37453, 5, 26, 1119, 6, 15117, 945, 4, 12, 8213, 313, 6, 3375, 245, 7, 5856, 19, 3, 262, 674, 4550, 3, 5, 137, 50, 13340, 1214, 72, 23394, 9, 20654, 6, 9474, 11, 4806, 4, 4374, 3231, 4, 19, 9988, 4, 6, 1250, 6, 3235, 2853, 8, 125, 10, 50, 80, 5, 2771, 31135, 4, 51610, 1307, 3, 191, 3, 365, 4, 12, 9759, 245, 7, 3051, 8877, 262, 3, 191, 1199, 169, 3, 191, 3780, 48, 367, 13580, 7, 2]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[183, 988, 24, 5, 32763, 7568, 8241, 6, 3, 3848, 763, 3, 5, 2048, 306, 7, 2069, 19, 8901, 245, 7, 3255, 3, 191, 15328, 234, 37453, 5, 26, 1119, 6, 15117, 945, 12, 8213, 313, 6, 3375, 245, 7, 5856, 19, 3, 262, 674, 4550, 3, 5, 137, 50, 13340, 1214, 72, 23394, 9, 20654, 9474, 11, 4806, 4374, 1929, 41, 37, 19, 9988, 6, 1250, 6, 24353, 25, 2853, 8, 137, 163, 80, 5, 2771, 31135, 51610, 1307, 3, 191, 3, 365, 12, 9113, 245, 7, 3051, 8877, 262, 3, 191, 1199, 169, 3, 191, 3780, 48, 367, 13580, 2]\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenized_dataset[0]['input_ids']))\n",
        "print(len(tokenized_dataset[0]['labels']))\n",
        "# print(len(tokenized_dataset[0]['input_ids']))\n",
        "print(tokenized_dataset[0]['labels'])\n",
        "print(tokenized_dataset[0]['attention_mask'])\n",
        "print(tokenized_dataset[0]['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTSgd7LqDmpR",
        "outputId": "79fc329a-5fcc-4836-a1f6-77a2dd27bcd4"
      },
      "id": "YTSgd7LqDmpR",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from datasets import load_dataset\n",
        "import sacrebleu\n",
        "import evaluate\n",
        "\n",
        "# Ensure punkt tokenizer is available\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "\n",
        "# Load the ROUGE metric\n",
        "# rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "# Function to compute both ROUGE and BLEU metrics\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    # Decode preds and labels\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # # Tokenize sentences for ROUGE\n",
        "    # decoded_preds_for_rouge = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    # decoded_labels_for_rouge = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "    # # Compute ROUGE score\n",
        "    # rouge_result = rouge_metric.compute(predictions=decoded_preds_for_rouge, references=decoded_labels_for_rouge, use_stemmer=True)\n",
        "\n",
        "    # Tokenize sentences for BLEU\n",
        "    decoded_preds_for_bleu = [\" \".join(nltk.word_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels_for_bleu = [\" \".join(nltk.word_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "    # Compute BLEU score\n",
        "    bleu = sacrebleu.corpus_bleu(decoded_preds_for_bleu, [decoded_labels_for_bleu])\n",
        "    bleu_result = {\"bleu\": bleu.score}\n",
        "\n",
        "    # Combine ROUGE and BLEU results\n",
        "    # result = {**rouge_result, **bleu_result}\n",
        "        # result = {**rouge_result, **bleu_result}\n",
        "    return bleu_result\n",
        "\n",
        "# Example usage (adjust accordingly)\n",
        "# preds = ... (Your model predictions here)\n",
        "# labels = ... (Your true labels here)\n",
        "# eval_preds = (preds, labels)\n",
        "# metrics = compute_metrics(eval_preds)\n",
        "# print(metrics)\n"
      ],
      "metadata": {
        "id": "-yyL8UfkDnmA"
      },
      "id": "-yyL8UfkDnmA",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4abea542",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:15:10.366342Z",
          "iopub.status.busy": "2024-05-12T15:15:10.365740Z",
          "iopub.status.idle": "2024-05-12T15:15:11.251996Z",
          "shell.execute_reply": "2024-05-12T15:15:11.251233Z"
        },
        "papermill": {
          "duration": 0.901087,
          "end_time": "2024-05-12T15:15:11.253959",
          "exception": false,
          "start_time": "2024-05-12T15:15:10.352872",
          "status": "completed"
        },
        "tags": [],
        "id": "4abea542"
      },
      "outputs": [],
      "source": [
        "# nltk.download(\"punkt\", quiet=True)\n",
        "# metric = evaluate.load(\"rouge\")\n",
        "\n",
        "# def compute_metrics(eval_preds):\n",
        "#     preds, labels = eval_preds\n",
        "\n",
        "#    # decode preds and labels\n",
        "#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "#     decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "#    # rougeLSum expects newline after each sentence\n",
        "#     decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "#     decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "#     result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "#     return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2hdfU4FGBaB",
        "outputId": "d554f273-71c2-4661-fee7-a68f9dec34f0"
      },
      "id": "Q2hdfU4FGBaB",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3570e965",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:15:11.280795Z",
          "iopub.status.busy": "2024-05-12T15:15:11.280223Z",
          "iopub.status.idle": "2024-05-12T15:15:11.884723Z",
          "shell.execute_reply": "2024-05-12T15:15:11.883304Z"
        },
        "papermill": {
          "duration": 0.62009,
          "end_time": "2024-05-12T15:15:11.886856",
          "exception": false,
          "start_time": "2024-05-12T15:15:11.266766",
          "status": "completed"
        },
        "tags": [],
        "id": "3570e965"
      },
      "outputs": [],
      "source": [
        "# Global Parameters\n",
        "L_RATE = 3e-4\n",
        "BATCH_SIZE = 8\n",
        "PER_DEVICE_EVAL_BATCH = 4\n",
        "WEIGHT_DECAY = 0.01\n",
        "SAVE_TOTAL_LIM = 3\n",
        "NUM_EPOCHS = 1\n",
        "\n",
        "model.to(\"cuda\")\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "   output_dir=\"./kaggle/working/results\",\n",
        "   evaluation_strategy=\"epoch\",\n",
        "   learning_rate=L_RATE,\n",
        "   per_device_train_batch_size=BATCH_SIZE,\n",
        "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
        "   weight_decay=WEIGHT_DECAY,\n",
        "   save_total_limit=SAVE_TOTAL_LIM,\n",
        "   num_train_epochs=NUM_EPOCHS,\n",
        "   predict_with_generate=True,\n",
        "   push_to_hub=False,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=10000,\n",
        "   report_to='none')\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_dataset,\n",
        "   eval_dataset=tokenized_dataset_test,\n",
        "   tokenizer=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db9bdd83",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-12T15:15:11.913044Z",
          "iopub.status.busy": "2024-05-12T15:15:11.912744Z",
          "iopub.status.idle": "2024-05-12T22:36:45.298306Z",
          "shell.execute_reply": "2024-05-12T22:36:45.297385Z"
        },
        "papermill": {
          "duration": 26493.407977,
          "end_time": "2024-05-12T22:36:45.307391",
          "exception": false,
          "start_time": "2024-05-12T15:15:11.899414",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "db9bdd83",
        "outputId": "38ee37c4-2942-4679-c64c-1e582ebbcf50"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:06, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='85' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   85/12500 00:54 < 2:15:00, 1.53 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 26733.184452,
      "end_time": "2024-05-12T22:36:48.966249",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-05-12T15:11:15.781797",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}